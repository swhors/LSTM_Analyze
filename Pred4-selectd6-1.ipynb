{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with LSTM model (v4.6.1)\n",
    "<p style='text-align: right;'>with selectd6.csv</p>\n",
    "\n",
    "* history\n",
    "  * 2025/05/23 PM06:02 : 3번째 모델의 3번째 데이터를 사용\n",
    "  * 2025/05/27\n",
    "  * 2025/05/30 : v4.5.1 작성 시작\n",
    "  * 2025/06/04 : v4.5.2 last update\n",
    "  * 2025/06/04 : v4.6.1 작성 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install numpy pandas keras scikit-learn matplotlib scikeras\n",
    "from datetime import datetime\n",
    "print(f'restart kernel... {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restart kernel... 2025-06-04 10:51:35.034677\n",
      "['/home/swhors/jupyter-workspace/LSTM/$PWD', '/home/swhors/jupyter-workspace/finance', '/home/swhors/jupyter-workspace/finance/venv/lib/python3.11/site-paches', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/home/swhors/jupyter-workspace/finance/venv/lib/python3.11/site-packages', '/home/swhors/jupyter-workspace/LSTM']\n"
     ]
    }
   ],
   "source": [
    "def restart_kernel():\n",
    "    # Restart the kernet after libraries are loaded.\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f'restart kernel... {datetime.now()}')\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "restart_kernel()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(cwd)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported library. (2025-06-06 02:03:46.764980)\n"
     ]
    }
   ],
   "source": [
    "# load dependacies\n",
    "import os\n",
    "import time\n",
    "import resource\n",
    "from datetime import datetime\n",
    "from lib.globalvar import *\n",
    "from lib.data_loader import DataLoader\n",
    "from lib.small_predict import predict_small, print_predict_small\n",
    "from lib.activation import ActivationOutput, RecurrentActivation\n",
    "from lib.small_predict import build_and_predict, gen_multi_model, save_model, generate_metric\n",
    "from lib.common_env_sets import lstm_units, dense_units, steps, metrics, dropout\n",
    "from lib.common_env_sets import learning_rate, last_lstm_return_sequences\n",
    "from lib.common_env_sets import loss, output_dense_activation, epochs, rand_seed\n",
    "\n",
    "\n",
    "print(f\"imported library. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished to set environemnt. (2025-06-06 02:03:53.599804)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## 모델링 환경 설정\n",
    "##\n",
    "window=1 # default = 1 , help = \"time stamps\"\n",
    "data_dir='./csv/selectd6.csv'\n",
    "\n",
    "mode='predict' # help = \"back-test or predict\")\n",
    "\n",
    "mode2='sampling' # help = \"greed or sampling\")\n",
    "verb='verbose' # help = \"verbose or not_verb\")\n",
    "    \n",
    "training_length=0.95 # default = 0.9)\n",
    "from_pos = 0\n",
    "last = [[3, 4, 6, 8, 32, 42],\n",
    "        [8, 11, 14, 17, 36, 39],\n",
    "        [1, 5, 18, 20, 30, 35],\n",
    "        [7, 9, 24, 40, 42, 44],\n",
    "        [3, 6, 7, 11, 12, 17],\n",
    "        [3, 13, 28, 34, 38, 42],\n",
    "        [5, 12, 24, 29, 32, 42]]\n",
    "print(f\"finished to set environemnt. ({datetime.now()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to load data. 2025-06-06 02:03:55.559866\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = {\n",
    "    1: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=0,\n",
    "                  verbose=False\n",
    "                  ),\n",
    "    2: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=300,\n",
    "                  verbose=False\n",
    "                  )\n",
    "    }\n",
    "\n",
    "print(f'completed to load data. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to set env for all models. 2025-06-06 02:03:57.686414\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## layers\n",
    "## LSTM Neural 계층 선언\n",
    "###########\n",
    "datasets = [dataset_dicts[1], # 0\n",
    "            dataset_dicts[2], # 1\n",
    "           ]\n",
    "\n",
    "sel_date = datetime(2025, 5, 31, 20, 35)\n",
    "rans_seed = (sel_date.timestamp() / 10000000)\n",
    "\n",
    "lstm_args = {14: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                           \"dropout\": dropout[0],\n",
    "                           \"steps\": steps[0], # last output elements count\n",
    "                           \"metrics\": metrics[1],\n",
    "                           \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                           \"lstm_units\": lstm_units[2],\n",
    "                           \"dense_units\": dense_units[2],\n",
    "                           \"output_dense_activation\": output_dense_activation[3],\n",
    "                           \"loss\": loss[0],\n",
    "                           \"return_state\": False,\n",
    "                           \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                           },\n",
    "                 \"train\": {\"epochs\": epochs[2],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 0 #100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             44: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                           \"dropout\": dropout[0],\n",
    "                           \"steps\": steps[0], # last output elements count\n",
    "                           \"metrics\": metrics[0],\n",
    "                           \"last_lstm_return_sequences\": last_lstm_return_sequences[1],\n",
    "                           \"lstm_units\": lstm_units[2],\n",
    "                           \"dense_units\": dense_units[2],\n",
    "                           \"output_dense_activation\": output_dense_activation[3],\n",
    "                           \"loss\": loss[0],\n",
    "                           \"return_state\": False,\n",
    "                           \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                           },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 0 #100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             }\n",
    "lstm_args_4 = {4: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                            \"dropout\": dropout[1],\n",
    "                            \"steps\": steps[0], # last output elements count\n",
    "                            \"metrics\": metrics[0],\n",
    "                            \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                            \"lstm_units\": lstm_units[2],\n",
    "                            \"dense_units\": dense_units[2],\n",
    "                            \"output_dense_activation\": output_dense_activation[3],\n",
    "                            \"loss\": loss[1],\n",
    "                            \"return_state\": False,\n",
    "                            \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                            },\n",
    "                   \"train\": {\"epochs\": epochs[3],\n",
    "                             \"is_shuffle\": False,\n",
    "                             \"batch\": 3,\n",
    "                             \"steps_per_epoch\": 90 #100\n",
    "                             },\n",
    "                   \"dataset\": datasets[0]\n",
    "                   },\n",
    "             }\n",
    "lstm_args_14 = {14: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                              \"dropout\": dropout[0],\n",
    "                              \"steps\": steps[0], # last output elements count\n",
    "                              \"metrics\": metrics[1],\n",
    "                              \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                              \"lstm_units\": lstm_units[2],\n",
    "                              \"dense_units\": dense_units[2],\n",
    "                              \"output_dense_activation\": output_dense_activation[3],\n",
    "                              \"loss\": loss[0],\n",
    "                              \"return_state\": False,\n",
    "                              \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                              },\n",
    "                     \"train\": {\"epochs\": epochs[2],\n",
    "                               \"is_shuffle\": False,\n",
    "                               \"batch\": 1,\n",
    "                               \"steps_per_epoch\": 0 #100\n",
    "                               },\n",
    "                     \"dataset\": datasets[0]\n",
    "                     },\n",
    "                }\n",
    "\n",
    "lstm_args_44 = {44: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                              \"dropout\": dropout[0],\n",
    "                              \"steps\": steps[0], # last output elements count\n",
    "                              \"metrics\": metrics[0],\n",
    "                              \"last_lstm_return_sequences\": last_lstm_return_sequences[1],\n",
    "                              \"lstm_units\": lstm_units[2],\n",
    "                              \"dense_units\": dense_units[2],\n",
    "                              \"output_dense_activation\": output_dense_activation[3],\n",
    "                              \"loss\": loss[0],\n",
    "                              \"return_state\": False,\n",
    "                              \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                              },\n",
    "                     \"train\": {\"epochs\": epochs[3],\n",
    "                               \"is_shuffle\": False,\n",
    "                               \"batch\": 1,\n",
    "                               \"steps_per_epoch\": 0 #100\n",
    "                               },\n",
    "                     \"dataset\": datasets[0]\n",
    "                     },\n",
    "                }\n",
    "\n",
    "lstm_args_2 = {2: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                            \"dropout\": dropout[0],\n",
    "                            \"steps\": steps[0], # last output elements count\n",
    "                            \"metrics\": metrics[0],\n",
    "                            \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                            \"lstm_units\": lstm_units[1],\n",
    "                            \"dense_units\": dense_units[1],\n",
    "                            \"output_dense_activation\": output_dense_activation[0],\n",
    "                            \"loss\": loss[0],\n",
    "                            \"rand_seed\": rans_seed\n",
    "                            },\n",
    "                   \"train\": {\"epochs\": epochs[1],\n",
    "                             \"is_shuffle\": False,\n",
    "                             \"batch\": 1,\n",
    "                             \"steps_per_epoch\": 1\n",
    "                             },\n",
    "                   \"dataset\": datasets[0]\n",
    "                   },\n",
    "             }\n",
    "\n",
    "lstm_args_6 = {6: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                            \"dropout\": dropout[1],\n",
    "                            \"steps\": steps[0], # last output elements count\n",
    "                            \"metrics\": metrics[0],\n",
    "                            \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                            \"lstm_units\": lstm_units[5],\n",
    "                            \"dense_units\": dense_units[4],\n",
    "                            \"output_dense_activation\": output_dense_activation[3],\n",
    "                            \"loss\": loss[1],\n",
    "                            \"return_state\": False,\n",
    "                            \"lstm_model\": \"Bidirectional\",\n",
    "                            \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                            },\n",
    "                   \"train\": {\"epochs\": epochs[3],\n",
    "                             \"is_shuffle\": False,\n",
    "                             \"batch\": 3,\n",
    "                             \"steps_per_epoch\": 90 #100\n",
    "                             },\n",
    "                   \"dataset\": datasets[0]\n",
    "                   }\n",
    "             }\n",
    "\n",
    "print(f'completed to set env for all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_metric(test_id, gen_num, round_limit, lstm_args=lstm_args):\n",
    "    \"\"\" gen_metric \"\"\"\n",
    "    model_version_from = 1\n",
    "    model_version_end = 1\n",
    "    print(f'gen_metric.step.0 [{datetime.now()}]')\n",
    "    args = {'test_id': test_id,\n",
    "            'version': model_version_from,\n",
    "            'write_to_db': True,\n",
    "            'last': last,\n",
    "            'mode2': mode2,\n",
    "            'gen_num': gen_num,\n",
    "            'round_limit': round_limit,\n",
    "            'db_file_name': \"./db/metrics.db\"\n",
    "            }\n",
    "    print(f'gen_metric.step.1 [{datetime.now()}]')\n",
    "    generate_metric(args=args,\n",
    "                    from_version=model_version_from,\n",
    "                    to_version=model_version_end,\n",
    "                    lstm_args=lstm_args)\n",
    "    print(f'gen_metric.step.2 [{datetime.now()}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Start: 1~1\n",
      "CPU 시간: 4.295898 초\n",
      "메모리 사용량: 616144 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 15:41:39.300424\n",
      "********************\n",
      "start to train all models. 2025-06-05 15:41:39.300454\n",
      "14's training. status=start 2025-06-05 15:41:39.300470\n",
      "14's training. status=end 2025-06-05 15:42:29.403099\n",
      "44's training. status=start 2025-06-05 15:42:29.403201\n",
      "44's training. status=end 2025-06-05 15:44:00.291719\n",
      "completed to train all models. 2025-06-05 15:44:00.291818\n",
      "train to create model(1). 2025-06-05 15:44:03.291901\n",
      "CPU 시간: 444.326674 초\n",
      "메모리 사용량: 1066912 KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_1'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 16:35:17.115076]\n",
      "gen_metric.step.1 [2025-06-05 16:35:17.115151]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 887.653416 초\n",
      "메모리 사용량: 1162592 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 16:35:17.115241\n",
      "********************\n",
      "start to train all models. 2025-06-05 16:35:17.115260\n",
      "14's training. status=start 2025-06-05 16:35:17.115277\n",
      "14's training. status=end 2025-06-05 16:36:06.258793\n",
      "completed to train all models. 2025-06-05 16:36:06.259092\n",
      "train to create model(1). 2025-06-05 16:36:09.259175\n",
      "CPU 시간: 1085.954814 초\n",
      "메모리 사용량: 1259808 KB\n",
      "gen_metric.step.2 [2025-06-05 16:39:02.396592]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_2'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 15:54:24.916540]\n",
      "gen_metric.step.1 [2025-06-05 15:54:24.916597]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 643.848371 초\n",
      "메모리 사용량: 1069264 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 15:54:24.916656\n",
      "********************\n",
      "start to train all models. 2025-06-05 15:54:24.916666\n",
      "44's training. status=start 2025-06-05 15:54:24.916676\n",
      "44's training. status=end 2025-06-05 15:55:54.581077\n",
      "completed to train all models. 2025-06-05 15:55:54.581205\n",
      "train to create model(1). 2025-06-05 15:55:57.581298\n",
      "CPU 시간: 886.626137 초\n",
      "메모리 사용량: 1162592 KB\n",
      "gen_metric.step.2 [2025-06-05 15:58:51.713842]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_3'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 18:03:06.790972]\n",
      "gen_metric.step.1 [2025-06-05 18:03:06.791049]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 1087.019035 초\n",
      "메모리 사용량: 1259808 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 18:03:06.791137\n",
      "********************\n",
      "start to train all models. 2025-06-05 18:03:06.791153\n",
      "4's training. status=start 2025-06-05 18:03:06.791167\n",
      "4's training. status=end 2025-06-05 18:04:01.033005\n",
      "completed to train all models. 2025-06-05 18:04:01.033137\n",
      "train to create model(1). 2025-06-05 18:04:04.033231\n",
      "CPU 시간: 1281.096318 초\n",
      "메모리 사용량: 1395776 KB\n",
      "gen_metric.step.2 [2025-06-05 18:06:54.907379]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_4'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 18:03:06.790972]\n",
      "gen_metric.step.1 [2025-06-05 18:03:06.791049]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 1087.019035 초\n",
      "메모리 사용량: 1259808 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 18:03:06.791137\n",
      "********************\n",
      "start to train all models. 2025-06-05 18:03:06.791153\n",
      "4's training. status=start 2025-06-05 18:03:06.791167\n",
      "4's training. status=end 2025-06-05 18:04:01.033005\n",
      "completed to train all models. 2025-06-05 18:04:01.033137\n",
      "train to create model(1). 2025-06-05 18:04:04.033231\n",
      "CPU 시간: 1281.096318 초\n",
      "메모리 사용량: 1395776 KB\n",
      "gen_metric.step.2 [2025-06-05 18:06:54.907379]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_5'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-06 02:04:06.727261]\n",
      "gen_metric.step.1 [2025-06-06 02:04:06.727746]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 1.78125 초\n",
      "메모리 사용량: 374760 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-06 02:04:06.727820\n",
      "********************\n",
      "start to train all models. 2025-06-06 02:04:06.727829\n",
      "6's training. status=start 2025-06-06 02:04:06.727837\n",
      "6's training. status=end 2025-06-06 02:04:16.525473\n",
      "completed to train all models. 2025-06-06 02:04:16.525559\n",
      "train to create model(1). 2025-06-06 02:04:19.525649\n",
      "INFO:tensorflow:Assets written to: ram://4feacfa172b64cebbc81751509f72303/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4feacfa172b64cebbc81751509f72303/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 시간: 35.375 초\n",
      "메모리 사용량: 1056312 KB\n",
      "gen_metric.step.2 [2025-06-06 02:05:25.607029]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_6'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
