{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with LSTM model\n",
    "<p style='text-align: right;'>with selectd1.csv</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_kernel():\n",
    "    # Restart the kernet after libraries are loaded.\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f'restart kernel... {datetime.now()}')\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "from datetime import datetime\n",
    "print(f'restart kernel... {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restart kernel... 2025-05-14 10:36:20.115647\n"
     ]
    }
   ],
   "source": [
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependacies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from lib.globalvar import *\n",
    "from lib.data import DataLoader\n",
    "from lib.model1 import PredictLSTM1\n",
    "from lib.model2 import PredictLSTM2\n",
    "from lib.model3 import PredictLSTM3\n",
    "from lib.model4 import PredictLSTM4\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.util_pred import print_data\n",
    "from lib.util_pred import flat_data_with_sum, flat_data, get_frequency\n",
    "from lib.util_pred import save_model, import_mode\n",
    "from lib.util_pred import get_random_in_list\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"imported library. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished to set environemnt. (2025-05-14 10:36:56.609019)\n"
     ]
    }
   ],
   "source": [
    "model_classes = {'lstm1': PredictLSTM1,\n",
    "                 'lstm2': PredictLSTM2,\n",
    "                 'lstm3': PredictLSTM3,\n",
    "                 'lstm4': PredictLSTM4}\n",
    "\n",
    "window=1 # default = 1 , help = \"time stamps\"\n",
    "data_dir='./selectd2.csv'\n",
    "    \n",
    "mode='predict' # help = \"back-test or predict\")\n",
    "mode2='sampling' # help = \"greed or sampling\")\n",
    "verb='verbose' # help = \"verbose or not_verb\")\n",
    "    \n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=1 # default = 0.9)\n",
    "epoch=20 # default = 3\n",
    "batch=1 # default = 1\n",
    "model_type='lstm4' # help = \"lstm1 or lstm2\")\n",
    "hid_dim = 50\n",
    "print(f\"finished to set environemnt. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to load data. 2025-05-14 10:37:04.393621\n"
     ]
    }
   ],
   "source": [
    "# data prepare and set base model\n",
    "dataset = DataLoader(data_dir=data_dir,\n",
    "                     training_length=training_length,\n",
    "                     window_prev=window,\n",
    "                     mode=mode,\n",
    "                     from_pos=400\n",
    "                    )\n",
    "print(f'completed to load data. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aimmodev/bin/clearml/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "## layers\n",
    "\"\"\"\n",
    "Activation (Output):\n",
    "    linear: No activation, output is directly passed through.\n",
    "    relu: Rectified Linear Unit, max(x, 0).\n",
    "    sigmoid: Sigmoid function, output between 0 and 1.\n",
    "    tanh: Hyperbolic tangent, output between -1 and 1.\n",
    "    softmax: Normalizes output to a probability distribution.\n",
    "    elu: Exponential Linear Unit.\n",
    "    selu: Scaled Exponential Linear Unit.\n",
    "\n",
    "Recurrent Activation:\n",
    "    sigmoid: Commonly used for gates in LSTM.\n",
    "    hard_sigmoid: A faster, less computationally expensive version of sigmoid.\n",
    "    tanh: Can be used, but sigmoid is more typical for gates.\n",
    "\"\"\"\n",
    "layers = [LSTM(hid_dim,\n",
    "               input_shape=(dataset.train_X.shape[1], dataset.train_X.shape[2]),\n",
    "               activation=\"elu\",\n",
    "               return_sequences=True),\n",
    "          LSTM(hid_dim,\n",
    "               return_sequences=True,\n",
    "               activation=\"elu\"), #, recurrent_activation=\"tanh\"),\n",
    "          LSTM(hid_dim,\n",
    "               return_sequences=True,\n",
    "               activation=\"elu\"), #, recurrent_activation=\"tanh\"),\n",
    "          LSTM(hid_dim,\n",
    "               return_sequences=True,\n",
    "               activation=\"elu\"), #, recurrent_activation=\"tanh\"),\n",
    "          LSTM(hid_dim,\n",
    "               return_sequences=True,\n",
    "               activation=\"elu\"), #, recurrent_activation=\"tanh\"),\n",
    "          LSTM(hid_dim,\n",
    "               return_sequences=False,\n",
    "               activation=\"elu\",\n",
    "               recurrent_activation=\"hard_sigmoid\"),\n",
    "          Dense(45, activation='softmax'),\n",
    "          Dense(45, activation='sigmoid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to create model. 2025-05-13 13:44:50.475780\n",
      "args = <class 'list'>, [[<LSTM name=lstm, built=False>, <LSTM name=lstm_1, built=False>, <LSTM name=lstm_2, built=False>, <Dense name=dense, built=False>, <Dense name=dense_1, built=False>]]\n",
      "layers = <class 'list'>, [<LSTM name=lstm, built=False>, <LSTM name=lstm_1, built=False>, <LSTM name=lstm_2, built=False>, <Dense name=dense, built=False>, <Dense name=dense_1, built=False>]\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_1, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_2, built=False>\n",
      "layer = <class 'keras.src.layers.core.dense.Dense'>, <Dense name=dense, built=False>\n",
      "layer = <class 'keras.src.layers.core.dense.Dense'>, <Dense name=dense_1, built=False>\n",
      "PredictLSTM2.create_model <Sequential name=sequential, built=True>\n",
      "comleted to create model. 2025-05-13 13:44:50.538860\n"
     ]
    }
   ],
   "source": [
    "model_class = model_classes[model_type]\n",
    "print(f'start to create model. {datetime.now()}')\n",
    "model = model_class(dataset, hid_dim = hid_dim, verb = verb, args=[layers])\n",
    "print(f'comleted to create model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to create model. 2025-05-14 10:37:13.168555\n",
      "args = <class 'list'>, [[<LSTM name=lstm, built=False>, <LSTM name=lstm_1, built=False>, <LSTM name=lstm_2, built=False>, <LSTM name=lstm_3, built=False>, <LSTM name=lstm_4, built=False>, <LSTM name=lstm_5, built=False>, <Dense name=dense, built=False>, <Dense name=dense_1, built=False>]]\n",
      "layers = <class 'list'>, [<LSTM name=lstm, built=False>, <LSTM name=lstm_1, built=False>, <LSTM name=lstm_2, built=False>, <LSTM name=lstm_3, built=False>, <LSTM name=lstm_4, built=False>, <LSTM name=lstm_5, built=False>, <Dense name=dense, built=False>, <Dense name=dense_1, built=False>]\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_1, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_2, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_3, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_4, built=False>\n",
      "layer = <class 'keras.src.layers.rnn.lstm.LSTM'>, <LSTM name=lstm_5, built=False>\n",
      "layer = <class 'keras.src.layers.core.dense.Dense'>, <Dense name=dense, built=False>\n",
      "layer = <class 'keras.src.layers.core.dense.Dense'>, <Dense name=dense_1, built=False>\n",
      "PredictLSTM4.create_model <Sequential name=sequential, built=True>\n",
      "comleted to create model. 2025-05-14 10:37:13.263458\n"
     ]
    }
   ],
   "source": [
    "# case of model2\n",
    "\n",
    "model_class2 = model_classes[model_type]\n",
    "print(f'start to create model. {datetime.now()}')\n",
    "model2 = model_class2(dataset, hid_dim = hid_dim, verb = verb, args=[layers])\n",
    "print(f'comleted to create model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check to create model. 2025-05-13 14:20:16.895243\n"
     ]
    }
   ],
   "source": [
    "print(f'check to create model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# pass this.\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "hist = model.training(num_epoch = epoch, num_batch = batch)\n",
    "end_time = datetime.now()\n",
    "elapsed = end_time - start_time\n",
    "print(f'elapsed = {elapsed}')\n",
    "print(f'comleted to train model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.5659\n",
      "Epoch 2/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.3066\n",
      "Epoch 3/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0091 - loss: 0.2261\n",
      "Epoch 4/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0086 - loss: 0.1885\n",
      "Epoch 5/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0048 - loss: 0.1876\n",
      "Epoch 6/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0056 - loss: 0.1602\n",
      "Epoch 7/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.1638\n",
      "Epoch 8/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 7.8595e-04 - loss: 0.1772\n",
      "Epoch 9/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1680\n",
      "Epoch 10/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0081 - loss: 0.1601\n",
      "Epoch 11/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1647\n",
      "Epoch 12/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1861\n",
      "Epoch 13/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1638\n",
      "Epoch 14/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1569\n",
      "Epoch 15/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1628\n",
      "Epoch 16/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1591\n",
      "Epoch 17/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1517\n",
      "Epoch 18/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1574\n",
      "Epoch 19/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1679\n",
      "Epoch 20/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1736\n",
      "Epoch 21/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1710\n",
      "Epoch 22/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1731\n",
      "Epoch 23/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1621\n",
      "Epoch 24/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1661\n",
      "Epoch 25/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1624\n",
      "Epoch 26/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1700\n",
      "Epoch 27/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1576\n",
      "Epoch 28/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1381\n",
      "Epoch 29/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0046 - loss: 0.1361\n",
      "Epoch 30/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1291\n",
      "Epoch 31/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1217\n",
      "Epoch 32/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1207\n",
      "Epoch 33/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1257\n",
      "Epoch 34/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: 0.1226\n",
      "Epoch 35/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0022 - loss: 0.1197\n",
      "Epoch 36/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0041 - loss: 0.1224\n",
      "Epoch 37/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0013 - loss: 0.1234\n",
      "Epoch 38/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0025 - loss: 0.1397\n",
      "Epoch 39/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0017 - loss: 0.1188\n",
      "Epoch 40/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0028 - loss: 0.1181\n",
      "Epoch 41/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0021 - loss: 0.1239\n",
      "Epoch 42/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0036 - loss: 0.1125\n",
      "Epoch 43/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0227 - loss: 0.1213\n",
      "Epoch 44/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0044 - loss: 0.1074\n",
      "Epoch 45/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0069 - loss: 0.1161\n",
      "Epoch 46/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0117 - loss: 0.1058\n",
      "Epoch 47/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0115 - loss: 0.1245\n",
      "Epoch 48/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0136 - loss: 0.1230\n",
      "Epoch 49/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0076 - loss: 0.1221\n",
      "Epoch 50/50\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0099 - loss: 0.1076\n",
      "elapsed = 0:01:19.466558\n",
      "comleted to train model. 2025-05-14 10:38:41.043484\n"
     ]
    }
   ],
   "source": [
    "# case of model2\n",
    "\n",
    "# training\n",
    "# pass this.\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "hist = model2.training(num_epoch = 50, num_batch = 1)\n",
    "end_time = datetime.now()\n",
    "elapsed = end_time - start_time\n",
    "print(f'elapsed = {elapsed}')\n",
    "print(f'comleted to train model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comleted to predict model. 2025-05-13 07:07:01.105924\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "greed_prediction_number_set = model.predict_numbers(\"greed\", trial=1)\n",
    "random_pred_set = model.predict_randomely(trial=1)\n",
    "#print(f'prediction_number_set = {prediction_number_set}')\n",
    "print(f'comleted to predict model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,295</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,070</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m19,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)             │         \u001b[38;5;34m2,295\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)             │         \u001b[38;5;34m2,070\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">373,697</span> (1.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m373,697\u001b[0m (1.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,565</span> (486.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,565\u001b[0m (486.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">249,132</span> (973.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m249,132\u001b[0m (973.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# case of model2\n",
    "# model info\n",
    "print(f'{model2.model.summary()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arams = {'bootstrap': False,\n",
    "         'ccp_alpha': 0.0,\n",
    "         'criterion': 'squared_error',\n",
    "         'max_depth': 7,\n",
    "         'max_features': 'sqrt',\n",
    "         'max_leaf_nodes': None,\n",
    "         'max_samples': None,\n",
    "         'min_impurity_decrease': 0.0,\n",
    "         'min_samples_leaf': 1,\n",
    "         'min_samples_split': 50,\n",
    "         'min_weight_fraction_leaf': 0.0,\n",
    "         'monotonic_cst': None,\n",
    "         'n_estimators': 1000,\n",
    "         'n_jobs': -1,\n",
    "         'oob_score': False,\n",
    "         'random_state': None,\n",
    "         'verbose': 0,\n",
    "         'warm_start': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "mode = \"back-test\"\n",
    "if mode == 'back-test':\n",
    "    model.evaluate(prediction_number_set)\n",
    "    print(\"---------Random baseline-------------\")\n",
    "    model.evaluate(random_pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print result\n",
    "print_data(title='wanted_data',\n",
    "           data_set=[[3, 6, 7, 11, 12, 17]])\n",
    "print_data(title='random_predicted',\n",
    "           data_set=random_pred_set,\n",
    "           add_val=1, need_sort=True)\n",
    "# print_data(title='greed_predicted',\n",
    "#            data_set=greed_prediction_number_set,\n",
    "#            add_val=0, need_sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.chain object at 0x784bc6927c40>\n",
      "{np.int64(7): 1, np.int64(16): 1, np.int64(18): 1, np.int64(21): 1, np.int64(44): 1, np.int64(45): 1}\n"
     ]
    }
   ],
   "source": [
    "#flated_data = flat_data(prediction_number_set)\n",
    "import itertools\n",
    "flated_data = itertools.chain.from_iterable(greed_prediction_number_set)\n",
    "print(f'{flated_data}')\n",
    "frequency = get_frequency(flated_data)\n",
    "frequency_sorted = dict(sorted(frequency.items()))\n",
    "print(frequency_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasRegressor(\n",
      "\tmodel=<function create_model_cb at 0x784bd6ed3240>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=rmsprop\n",
      "\tloss=binary_crossentropy\n",
      "\tmetrics=None\n",
      "\tbatch_size=1\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=50\n",
      "\tlstm_units=45\n",
      "\tdense_units=45\n",
      "\ttrain_X=[[[0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. ... 1. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]]]\n",
      "\tactivation=softmax\n",
      "\tlearning_rate=0.001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x_axis = list(frequency_sorted.keys())\n",
    "y_axis = list(frequency_sorted.values())\n",
    "plt.bar(x_axis, y_axis)\n",
    "plt.xlabel(\"nums\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.title(\"frequency\")\n",
    "plt.show()\n",
    "print_data(title='wanted_data',\n",
    "           data_set=[[5, 12, 24, 26, 39, 42, 20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseLSTM.save_model\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'verb' of 'PredictLSTM3' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverb\u001b[49m = \u001b[33m\"\u001b[39m\u001b[33mNone\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m prediction_number_set3 = model.predict_numbers(mode2, trial=\u001b[32m5\u001b[39m, use_pre = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m prediction_number_set4 = model.predict_numbers(mode2, trial=\u001b[32m5\u001b[39m, use_pre = \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: property 'verb' of 'PredictLSTM3' object has no setter"
     ]
    }
   ],
   "source": [
    "# model.verb = \"None\"\n",
    "prediction_number_set3 = model.predict_numbers(mode2, trial=5, use_pre = True)\n",
    "prediction_number_set4 = model.predict_numbers(mode2, trial=5, use_pre = False)\n",
    "\n",
    "print_data(title='wanted_data',\n",
    "           data_set=[[3, 6, 7, 11, 12, 17],\n",
    "                    [5, 12, 24, 29, 32, 42],\n",
    "                    [12, 13, 21, 26, 29, 37]])\n",
    "print_data(title='prediction_number_set3',\n",
    "           data_set=prediction_number_set3,\n",
    "           add_val=0, need_sort=True)\n",
    "print_data1(title='prediction_number_set4',\n",
    "           data_set=prediction_number_set4,\n",
    "           add_val=0, need_sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.verb = \"None\"\n",
    "prediction_number_set = model.predict_numbers(mode2, trial=20, use_pre = True)\n",
    "\n",
    "print_data(title='wanted_data',\n",
    "           data_set=[[3, 6, 7, 11, 12, 17],\n",
    "                     [3, 13, 28, 34, 38, 42],\n",
    "                     [5, 12, 24, 29, 32, 42]])\n",
    "print('-----')\n",
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')\n",
    "print_data1(title=\"predicted_all\", data_set=prediction_number_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.verb = \"None\"\n",
    "prediction_number_set2 = model.predict_numbers(mode2, trial=40, use_pre = False)\n",
    "\n",
    "print_data(title='wanted_data',\n",
    "           data_set=[[3, 6, 7, 11, 12, 17],\n",
    "                     [3, 13, 28, 34, 38, 42],\n",
    "                     [5, 12, 24, 29, 32, 42]])\n",
    "print('-----')\n",
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set2, 5)}')\n",
    "print_data1(title=\"predicted_all\", data_set=prediction_number_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : [1, 9, 17, 18, 24, 28]\n",
      "1 : [4, 7, 14, 15, 29, 35]\n",
      "2 : [7, 34, 37, 39, 41, 43]\n",
      "3 : [8, 9, 10, 14, 18, 27]\n",
      "4 : [1, 11, 18, 20, 25, 33]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set2, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(title='greed_predicted',\n",
    "           data_set=greed_prediction_number_set,\n",
    "           add_val=0, need_sort=True)\n",
    "print(f'greed_prediction_number_set\\n\\t\\t{greed_prediction_number_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when \n",
    "\"\"\"\n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=1 # default = 0.9)\n",
    "epoch=100 # default = 3\n",
    "batch=3 # default = 1\n",
    "model='lstm2' # help = \"lstm or lstm2\")\n",
    "hid_dim = 128\n",
    "\"\"\"\n",
    "for i in range(6):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model={model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pred_set = model.predict_randomely(trial=1)\n",
    "print(f'prediction_number_set = {random_pred_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1170 : 3·13·28·34·38·42\n",
    "\n",
    "last = [\n",
    "    [6, 8, 37, 40, 41, 44],\n",
    "    [8, 10, 20, 25, 33, 37],\n",
    "    [4, 18, 27, 32, 40, 43],\n",
    "    [2, 8, 10, 31, 33, 35],\n",
    "    [15, 20, 28, 38, 41, 45],\n",
    "    [12, 26, 13, 5, 31, 38]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1171 : [3, 6, 7, 11, 12, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
