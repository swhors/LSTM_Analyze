{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with LSTM model v01\n",
    "<p style='text-align: right;'>with selectd3.csv</p>\n",
    "\n",
    "* history\n",
    "  * 2025/05/16 PM06:56 : 4번째 모델의 8번째 데이터를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_kernel():\n",
    "    # Restart the kernet after libraries are loaded.\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f'restart kernel... {datetime.now()}')\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "from datetime import datetime\n",
    "print(f'restart kernel... {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restart kernel... 2025-05-15 17:06:07.360561\n"
     ]
    }
   ],
   "source": [
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported library. (2025-05-16 18:14:30.575871)\n"
     ]
    }
   ],
   "source": [
    "# load dependacies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from globalvar import *\n",
    "from data import DataLoader\n",
    "from model1 import PredictLSTM1\n",
    "from model2 import PredictLSTM2\n",
    "from model3 import PredictLSTM3\n",
    "from model4 import PredictLSTM4\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util_pred import print_data\n",
    "from util_pred import flat_data_with_sum, flat_data, get_frequency\n",
    "from util_pred import save_model, import_mode\n",
    "from util_pred import get_random_in_list\n",
    "from util_pred import print_data_with_sort\n",
    "from util_pred import get_sorted_n_values\n",
    "from util_pred import dict_key_count\n",
    "from util_pred import print_list\n",
    "from util_pred import print_dict_list\n",
    "from util_pred import print_title\n",
    "from activation import ActivationOutput, RecurrentActivation\n",
    "from datetime import datetime\n",
    "\n",
    "from operate import create_model, create_model_v1, get_predicted\n",
    "\n",
    "print(f\"imported library. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished to set environemnt. (2025-05-19 10:52:48.827199)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## 모델링 환경 설정\n",
    "##\n",
    "window=1 # default = 1 , help = \"time stamps\"\n",
    "data_dir='./selectd3.csv'\n",
    "    \n",
    "mode='predict' # help = \"back-test or predict\")\n",
    "mode2='sampling' # help = \"greed or sampling\")\n",
    "verb='verbose' # help = \"verbose or not_verb\")\n",
    "    \n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=1 # default = 0.9)\n",
    "epoch=20 # default = 3\n",
    "batch=1 # default = 1\n",
    "model_type='lstm4' # help = \"lstm1 or lstm2\")\n",
    "hid_dim = 50\n",
    "from_pos = 0\n",
    "last = [[7, 9, 24, 40, 42, 44],\n",
    "        [3, 6, 7, 11, 12, 17],\n",
    "        [3, 13, 28, 34, 38, 42],\n",
    "        [5, 12, 24, 29, 32, 42]]\n",
    "print(f\"finished to set environemnt. ({datetime.now()})\")\n",
    "MAX_MODEL_CNT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_lstm_model(\n",
    "    self,\n",
    "    seq_len: int,\n",
    "    n_features: int,\n",
    "    lstm_units: list,\n",
    "    learning_rate: float,\n",
    "    dropout: float,\n",
    "    steps: int,\n",
    "    metrics: str,\n",
    "    single_output: bool,\n",
    "    last_lstm_return_sequences: bool = False,\n",
    "    dense_units: list = None,\n",
    "    activation: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    LSTM 네트워크를 생성한 결과를 반환한다.\n",
    "\n",
    "    :param seq_len: Length of sequences. (Look back window size)\n",
    "    :param n_features: Number of features. It requires for model input shape.\n",
    "    :param lstm_units: Number of cells each LSTM layers.\n",
    "    :param learning_rate: Learning rate.\n",
    "    :param dropout: Dropout rate.\n",
    "    :param steps: Length to predict.\n",
    "    :param metrics: Model loss function metric.\n",
    "    :param single_output: Whether 'yhat' is a multiple value or a single value.\n",
    "    :param last_lstm_return_sequences: Last LSTM's `return_sequences`. Allow when `single_output=False` only.\n",
    "    :param dense_units: Number of cells each Dense layers. It adds after LSTM layers.\n",
    "    :param activation: Activation function of Layers.\n",
    "    \"\"\"\n",
    "    tf.random.set_seed(self.random_seed)\n",
    "    model = Sequential()\n",
    "\n",
    "    if len(lstm_units) > 1:\n",
    "        # LSTM -> ... -> LSTM -> Dense(steps)\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                units=lstm_units[0],\n",
    "                activation=activation,\n",
    "                return_sequences=True,\n",
    "                input_shape=(seq_len, n_features),\n",
    "            )\n",
    "        )\n",
    "        lstm_layers = lstm_units[1:]\n",
    "        for i, n_units in enumerate(lstm_layers, start=1):\n",
    "            if i == len(lstm_layers):\n",
    "                if single_output:\n",
    "                    return_sequences = False\n",
    "                else:\n",
    "                    return_sequences = last_lstm_return_sequences\n",
    "                model.add(\n",
    "                    LSTM(\n",
    "                        units=n_units,\n",
    "                        activation=activation,\n",
    "                        return_sequences=return_sequences,\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                model.add(\n",
    "                    LSTM(\n",
    "                        units=n_units,\n",
    "                        activation=activation,\n",
    "                        return_sequences=True,\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        # LSTM -> Dense(steps)\n",
    "        if single_output:\n",
    "            return_sequences = False\n",
    "        else:\n",
    "            return_sequences = last_lstm_return_sequences\n",
    "        model.add(\n",
    "            LSTM(\n",
    "                units=lstm_units[0],\n",
    "                activation=activation,\n",
    "                return_sequences=return_sequences,\n",
    "                input_shape=(seq_len, n_features),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if single_output:  # Single Step, Direct Multi Step\n",
    "        if dense_units:\n",
    "            for n_units in dense_units:\n",
    "                model.add(Dense(units=n_units, activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(rate=dropout))\n",
    "        model.add(Dense(1))\n",
    "    else:  # Multiple Output Step\n",
    "        if last_lstm_return_sequences:\n",
    "            model.add(Flatten())\n",
    "        if dense_units:\n",
    "            for n_units in dense_units:\n",
    "                model.add(Dense(units=n_units, activation=activation))\n",
    "        if dropout > 0:\n",
    "            model.add(Dropout(rate=dropout))\n",
    "        model.add(Dense(units=steps))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=MSE, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model = self.build_and_compile_lstm_model(\n",
    "        seq_len=seq_len,\n",
    "        n_features=n_features,\n",
    "        lstm_units=lstm_units,\n",
    "        activation=activation,\n",
    "        learning_rate=learning_rate,\n",
    "        dropout=dropout,\n",
    "        steps=steps,\n",
    "        last_lstm_return_sequences=last_lstm_return_sequences,\n",
    "        dense_units=dense_units,\n",
    "        metrics=metrics,\n",
    "        single_output=single_output,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader.preproc_csv origin = 571, [[ 601    2   16 ...   31   34   35]\n",
      " [ 602   13   14 ...   27   30   38]\n",
      " [ 603    2   19 ...   26   27   43]\n",
      " ...\n",
      " [1169    5   12 ...   26   39   42]\n",
      " [1170    3   13 ...   34   38   42]\n",
      " [1171    3    6 ...   11   12   17]]\n",
      "rDataLoader.preproc_csv aw_np_proc = 571, [[16 19 31 34 35]\n",
      " [14 22 27 30 38]\n",
      " [19 25 26 27 43]\n",
      " ...\n",
      " [12 24 26 39 42]\n",
      " [13 28 34 38 42]\n",
      " [ 6  7 11 12 17]]\n",
      "DataLoader.preproc_csv origin = 571, [[ 601    2   16 ...   31   34   35]\n",
      " [ 602   13   14 ...   27   30   38]\n",
      " [ 603    2   19 ...   26   27   43]\n",
      " ...\n",
      " [1169    5   12 ...   26   39   42]\n",
      " [1170    3   13 ...   34   38   42]\n",
      " [1171    3    6 ...   11   12   17]]\n",
      "rDataLoader.preproc_csv aw_np_proc = 571, [[16 19 31 34 35]\n",
      " [14 22 27 30 38]\n",
      " [19 25 26 27 43]\n",
      " ...\n",
      " [12 24 26 39 42]\n",
      " [13 28 34 38 42]\n",
      " [ 6  7 11 12 17]]\n",
      "DataLoader.preproc_csv origin = 571, [[ 601    2   16 ...   31   34   35]\n",
      " [ 602   13   14 ...   27   30   38]\n",
      " [ 603    2   19 ...   26   27   43]\n",
      " ...\n",
      " [1169    5   12 ...   26   39   42]\n",
      " [1170    3   13 ...   34   38   42]\n",
      " [1171    3    6 ...   11   12   17]]\n",
      "rDataLoader.preproc_csv aw_np_proc = 271, [[18 20 23 30 34]\n",
      " [19 23 24 36 39]\n",
      " [15 16 21 22 28]\n",
      " ...\n",
      " [12 24 26 39 42]\n",
      " [13 28 34 38 42]\n",
      " [ 6  7 11 12 17]]\n",
      "completed to load data. 2025-05-16 18:14:36.666613\n"
     ]
    }
   ],
   "source": [
    "# data prepare and set base model\n",
    "dataset = DataLoader(data_dir=data_dir,\n",
    "                     training_length=training_length,\n",
    "                     window_prev=window,\n",
    "                     mode=mode,\n",
    "                     from_pos=from_pos\n",
    "                    )\n",
    "\n",
    "dataset_dicts = {\n",
    "    1: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=0\n",
    "                  ),\n",
    "    2: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=300\n",
    "                  )\n",
    "    }\n",
    "print(f'completed to load data. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to set evn for all models. 2025-05-16 18:14:42.434422\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## layers\n",
    "## LSTM Neural 계층 선언\n",
    "###########\n",
    "\"\"\"\n",
    "Activation (Output):\n",
    "    linear: No activation, output is directly passed through.\n",
    "    relu: Rectified Linear Unit, max(x, 0).\n",
    "    sigmoid: Sigmoid function, output between 0 and 1.\n",
    "    tanh: Hyperbolic tangent, output between -1 and 1.\n",
    "    softmax: Normalizes output to a probability distribution.\n",
    "    elu: Exponential Linear Unit.\n",
    "    selu: Scaled Exponential Linear Unit.\n",
    "\n",
    "Recurrent Activation:\n",
    "    sigmoid: Commonly used for gates in LSTM.\n",
    "    hard_sigmoid: A faster, less computationally expensive version of sigmoid.\n",
    "    tanh: Can be used, but sigmoid is more typical for gates.\n",
    "\"\"\"\n",
    "lstm_layers = {\n",
    "    4: [LSTM(hid_dim,\n",
    "             activation=ActivationOutput.selu.name,\n",
    "             return_sequences=True),\n",
    "        LSTM(hid_dim,\n",
    "             return_sequences=True,\n",
    "             activation=ActivationOutput.selu.name),\n",
    "        LSTM(hid_dim,\n",
    "             return_sequences=True,\n",
    "             activation=ActivationOutput.sigmoid.name),\n",
    "        LSTM(hid_dim,\n",
    "             return_sequences=False,\n",
    "             activation=ActivationOutput.elu.name,\n",
    "             recurrent_activation=\"hard_sigmoid\")],\n",
    "    }\n",
    "\n",
    "simple_lstm_layer = [LSTM(hid_dim,\n",
    "                     activation=ActivationOutput.elu.name)]\n",
    "\n",
    "dense_layers = {0: [Dense(45, activation='softmax'),\n",
    "                    Dense(45, activation='sigmoid')],\n",
    "                7: [Dense(45, activation='softmax')]\n",
    "               }\n",
    "simple_dense_layer = [Dense(45, activation='softmax')]\n",
    "\n",
    "layers = [\n",
    "    lstm_layers[4] + dense_layers[7], # 4\n",
    "    lstm_layers[4] + dense_layers[0], # 5\n",
    "    lstm_layers[4] + dense_layers[7], # 4\n",
    "    lstm_layers[4] + dense_layers[0], # 5\n",
    "    lstm_layers[4] + dense_layers[7], # 4\n",
    "    lstm_layers[4] + dense_layers[0], # 5\n",
    "    ]\n",
    "\n",
    "datasets = [dataset_dicts[1], # 4\n",
    "            dataset_dicts[2], # 5\n",
    "            dataset_dicts[1], # 4\n",
    "            dataset_dicts[2], # 5\n",
    "            dataset_dicts[1], # 4\n",
    "            dataset_dicts[2], # 5\n",
    "           ]\n",
    "\n",
    "lstm_args = [\n",
    "    {\n",
    "            \"lstm_units=lstm_units,\n",
    "            \"learning_rate=learning_rate,\n",
    "            \"dropout=dropout,\n",
    "            \"steps=steps,\n",
    "            \"metrics=metrics,\n",
    "            \"last_lstm_return_sequences=False,\n",
    "            \"dense_units=[45],\n",
    "            \"activations=[\"softmax\"],\n",
    "            \"dense_activation=[\"softmax\"],\n",
    "            \"output_dense_activation=output_dense_activation\n",
    "    }\n",
    "]\n",
    "\n",
    "epochs = [20, 10, 25, 25, 100, 100]\n",
    "\n",
    "models = [None for i in range(MAX_MODEL_CNT)]\n",
    "#matched_cnts = [0 for i in range(MAX_MODEL_CNT)]\n",
    "#selected_fives = [None for i in range(MAX_MODEL_CNT)]\n",
    "#matched_list = [None for i in range(MAX_MODEL_CNT)]\n",
    "#predicted_all = [None for i in range(MAX_MODEL_CNT)]\n",
    "\n",
    "matched_cnts = {}\n",
    "selected_fives = {}\n",
    "matched_list = {}\n",
    "predicted_all = {}\n",
    "\n",
    "print(f'completed to set evn for all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to train all models. 2025-05-16 18:14:47.539282\n",
      "1's training. status=start 2025-05-16 18:14:47.539459\n",
      "1's training. status=end 2025-05-16 18:15:15.473533\n",
      "2's training. status=start 2025-05-16 18:15:15.473669\n",
      "2's training. status=end 2025-05-16 18:15:24.904533\n",
      "3's training. status=start 2025-05-16 18:15:24.904646\n",
      "3's training. status=end 2025-05-16 18:16:00.316994\n",
      "4's training. status=start 2025-05-16 18:16:00.317133\n",
      "4's training. status=end 2025-05-16 18:16:17.799789\n",
      "5's training. status=start 2025-05-16 18:16:17.799893\n",
      "5's training. status=end 2025-05-16 18:18:30.151002\n",
      "6's training. status=start 2025-05-16 18:18:30.151112\n",
      "6's training. status=end 2025-05-16 18:19:34.904407\n",
      "completed to train all models. 2025-05-16 18:19:34.905147\n"
     ]
    }
   ],
   "source": [
    "# all : create model and training\n",
    "print(f'start to train all models. {datetime.now()}')\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    print(f'{i+1}\\'s training. status=start {datetime.now()}')\n",
    "    model = create_model(id=i,\n",
    "                         model_type=\"lstm4\",\n",
    "                         layers=layers[i],\n",
    "                         dataset=datasets[i],\n",
    "                         hid_dim=hid_dim,\n",
    "                         epoch=epochs[i],\n",
    "                         verbose=False\n",
    "                        )\n",
    "    models[i] = (model, layers[i])\n",
    "    print(f'{i+1}\\'s training. status=end {datetime.now()}')\n",
    "print(f'completed to train all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check to create model. 2025-05-16 16:59:31.699518\n"
     ]
    }
   ],
   "source": [
    "print(f'check to create model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : predict #1\n",
    "greed_prediction = [None for i in range(MAX_MODEL_CNT)]\n",
    "random_pred = [None for i in range(MAX_MODEL_CNT)]\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    greed_prediction[i] = models[i][0].predict_numbers(\"greed\", trial=1)\n",
    "    random_pred[i] = models[i][0].predict_randomely(trial=1)\n",
    "    print(f'{i+1}\\'s greed_prediction = {greed_prediction[i]}')\n",
    "    print(f'{i+1}\\'s random_pred = {random_pred[i]}')\n",
    "print(f'comleted to predict model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_cnts, selected_fives, matched_list, predicted_all = repeat_predict_all_model(trial=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_cnts)\n",
    "print(matched_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def listinlist_2_strinlist(list_in_list):\n",
    "    \"\"\" listinlist_2_strinlist \"\"\"\n",
    "    str_in_list = []\n",
    "    for l in list_in_list:\n",
    "        str_in_list.append(\",\".join(l))\n",
    "    return str_in_list      \n",
    "\n",
    "\n",
    "def change_matched_info(matched_count, matched_list):\n",
    "    counts = {}\n",
    "    cnt = 1\n",
    "    for c in matched_count:\n",
    "        counts[cnt] = \",\".join([ str(i) for i in c])\n",
    "        cnt += 1\n",
    "    cnt = 1\n",
    "    datas = {}\n",
    "    for d in matched_list:\n",
    "        datas[cnt] = d\n",
    "        cnt += 1\n",
    "    return counts, datas\n",
    "\n",
    "def write_json(trial, matched_count, matched_list, append=False):\n",
    "    suffix = datetime.now().strftime('%y%m%d_%H')\n",
    "    file_name = f\"matched_{suffix}.json\"\n",
    "    matched_dict = {}\n",
    "    if append:\n",
    "        if os.path.isfile(file_name):\n",
    "            with open(file_name, \"r\") as file:\n",
    "                matched_dict = json.load(file)\n",
    "                file.close()\n",
    "    counts, datas = change_matched_info(matched_count, matched_list)\n",
    "    if len(counts) > 0 and len(datas) > 0:\n",
    "        matched_dict[trial] = {}\n",
    "        matched_dict[trial][\"counts\"] =  counts\n",
    "        matched_dict[trial][\"datas\"] = datas\n",
    "        print(f'matched_dict = {matched_dict}')\n",
    "        with open(file_name, \"w\") as file:\n",
    "            json.dump(matched_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all with trial : print predicted\n",
    "write_json(trial = 3, matched_count=matched_cnts, matched_list=matched_list, append=True)\n",
    "print_dict_list(title=\"matched_cnt\", datas=matched_cnts)\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    print_list(title=f\"matched_list[{i+1}]\", datas=matched_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 회차 | 3이상 ||| 0이 없음 |\n",
    "| -- | -- | -- | -- | -- |\n",
    "|  1 | N ||| 2 |\n",
    "|  2 | N ||| 1 |\n",
    "|  3 | **1**, 2 ||| **1** |\n",
    "|  4 | N ||| N |\n",
    "|  5 | N ||| N |\n",
    "|  6 | N ||| N |\n",
    "|  7 | N ||| N |\n",
    "|  8 | 2 ||| N |\n",
    "\n",
    "|  8 | 1 ||| N |\n",
    "|  8 | N ||| N |\n",
    "|  8 | N ||| N |\n",
    "|  8 | 2 ||| N |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "{14:6, 13:8, 12:4, _11:10_, 10:3, 9:1, 8:6, 7:5, 6:4, 5:9, 4:4, 3:7, 2:7, 1:4}\n",
    "## 4시 40분경 데이터\n",
    "- {2: 6, 5: 5, 6: 4, 4: 3, 3: 3, 1: 2}\n",
    "- {6: 4, 5: 5, 4: 3, 3: 3, 2: 6, 1: 2}\n",
    "\n",
    "## 5시 20분경 데이터\n",
    "- {4: 5, 5: 5, 1: 4, 6: 3, 3: 2}\n",
    "- {6: 3, 5: 5, 4: 5, 3: 2, 1: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all (SMALL): predict #2\n",
    "def predict_small(trial, last, models):\n",
    "    matched_cnts_small = [0 for i in range(MAX_MODEL_CNT)]\n",
    "    selected_fives_small = [None for i in range(MAX_MODEL_CNT)]\n",
    "    matched_list_small = [None for i in range(MAX_MODEL_CNT)]\n",
    "    predicted_all_small = [None for i in range(MAX_MODEL_CNT)]\n",
    "\n",
    "    for i in range(MAX_MODEL_CNT):\n",
    "        title = f\"history #{i+1}\"\n",
    "        model_num = i\n",
    "        if models[model_num] is None:\n",
    "            print(f\"model #{model_num+1} is None\")\n",
    "        else:\n",
    "            models[model_num][0].verb = \"None\"\n",
    "            matched_cnts_small[model_num], \\\n",
    "            selected_fives_small[model_num], \\\n",
    "            matched_list_small[model_num], \\\n",
    "            predicted_all_small[model_num] = get_predicted(\n",
    "                title=title,\n",
    "                model=models[model_num][0],\n",
    "                mode=mode2,\n",
    "                use_pre=False,\n",
    "                last=last,\n",
    "                verbose=False,\n",
    "                trial=5\n",
    "            )\n",
    "    print(f'predicted time : trial={trial} date={datetime.now()}')\n",
    "    return matched_cnts_small, matched_list_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all (SMALL): print predicted\n",
    "def print_predict_small(matched_cnts_small, matched_list_small):\n",
    "    print(f'print time : {datetime.now()}')\n",
    "    #write_json(trial = 3, matched_count=matched_cnts_small, matched_list=matched_list_small, append=True)\n",
    "    print_dict_list(title=\"matched_cnt\", datas=matched_cnts_small)\n",
    "    for i in range(MAX_MODEL_CNT):\n",
    "        print_list(title=f\"matched_list[{i+1}]\", datas=matched_list_small[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "predicted time : trial=1 date=2025-05-19 10:54:28.092458\n"
     ]
    }
   ],
   "source": [
    "trial = 1\n",
    "matched_cnts_all = []\n",
    "matched_list = []\n",
    "for t in range(1, trial+1):\n",
    "    matched_cnts_small, matched_list_small = predict_small(trial=t, last=last, models=models)\n",
    "    #print_predict_small(matched_cnts_small, matched_list_small)\n",
    "    matched_cnts_all.append(matched_cnts_small)\n",
    "    matched_list.append(matched_list_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_matched_1_model_1\n",
      "\t([16, 25, 36, 40, 41, 44], [40, 44])\n",
      "\t([29, 31, 5, 44, 18, 38], [44])\n",
      "\t([26, 23, 30, 36, 21, 2], [])\n",
      "\t([7, 15, 21, 22, 37, 42], [7, 42])\n",
      "\t([3, 11, 18, 30, 35, 8], [])\n",
      "total_matched_1_model_2\n",
      "\t([6, 16, 23, 32, 44, 45], [44])\n",
      "\t([17, 41, 18, 35, 31, 12], [])\n",
      "\t([6, 12, 15, 17, 32, 38], [])\n",
      "\t([28, 4, 31, 39, 2, 21], [])\n",
      "\t([5, 19, 23, 39, 42, 44], [42, 44])\n",
      "total_matched_1_model_3\n",
      "\t([30, 1, 18, 5, 7, 41], [7])\n",
      "\t([2, 3, 6, 14, 24, 45], [24])\n",
      "\t([2, 7, 13, 14, 27, 36], [7])\n",
      "\t([19, 14, 22, 6, 23, 45], [])\n",
      "\t([8, 19, 34, 35, 40, 42], [40, 42])\n",
      "total_matched_1_model_4\n",
      "\t([1, 11, 12, 15, 21, 36], [])\n",
      "\t([11, 31, 34, 36, 37, 42], [42])\n",
      "\t([2, 6, 7, 16, 40, 45], [7, 40])\n",
      "\t([29, 36, 33, 44, 2, 7], [7, 44])\n",
      "\t([5, 7, 22, 30, 37, 41], [7])\n",
      "total_matched_1_model_5\n",
      "\t([2, 15, 22, 33, 37, 40], [40])\n",
      "\t([6, 4, 33, 42, 17, 29], [42])\n",
      "\t([2, 16, 23, 30, 38, 45], [])\n",
      "\t([26, 41, 44, 16, 2, 36], [44])\n",
      "\t([38, 41, 11, 5, 12, 28], [])\n",
      "total_matched_1_model_6\n",
      "\t([29, 2, 30, 23, 42, 6], [42])\n",
      "\t([8, 16, 27, 34, 35, 45], [])\n",
      "\t([3, 11, 13, 16, 19, 44], [44])\n",
      "\t([1, 2, 12, 19, 22, 44], [44])\n",
      "\t([7, 10, 17, 28, 41, 45], [7])\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "for matched in matched_list:\n",
    "    cnt1 = 1\n",
    "    for m in matched:\n",
    "        print_list(title=f\"total_matched_{cnt}_model_{cnt1}\", datas=m)\n",
    "        cnt1 += 1\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([3, 5, 10, 11, 13, 26], [3, 11]),\n",
    "([36, 10, 7, 32, 1, 11], [7, 11]),\n",
    "([20, 41, 21, 14, 6, 40], [6]),\n",
    "([12, 15, 19, 21, 34, 36], [12]),\n",
    "([27, 40, 35, 5, 45, 37], [])]\n",
    "\n",
    "\n",
    "([3, 9, 11, 28, 29, 30], [3, 11]),\n",
    "([1, 6, 12, 22, 28, 32], [6, 12]),\n",
    "([1, 11, 25, 28, 32, 45], [11]),\n",
    "([7, 22, 27, 28, 38, 39], [7]),\n",
    "([39, 12, 24, 11, 31, 25], [11, 12])\n",
    "\n",
    "\n",
    "([3, 4, 8, 21, 26, 27], [3]),\n",
    "([3, 4, 14, 18, 28, 37], [3]),\n",
    "([3, 15, 17, 23, 33, 36], [3, 17]),\n",
    "([44, 30, 5, 41, 10, 3], [3]),\n",
    "([1, 6, 13, 17, 30, 45], [6, 17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : save model\n",
    "for model in models:\n",
    "    if model is not None:\n",
    "        model[0].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : model info\n",
    "#################\n",
    "# model info\n",
    "#################\n",
    "for model in models:\n",
    "    if model is not None:\n",
    "        print(f'model:\\n\\t{model[0].model.summary()}')\n",
    "        print(f'layer:\\n\\t{model[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : model test\n",
    "mode = \"back-test\"\n",
    "if mode == 'back-test':\n",
    "    for model in models:\n",
    "        if model is not None:\n",
    "            greed_prediction_number_set = model[0].predict_numbers(\"greed\", trial=1)\n",
    "            random_pred_set = model[0].predict_randomely(trial=1)\n",
    "            model[0].evaluate(greed_prediction_number_set)\n",
    "            print(\"---------Random baseline-------------\")\n",
    "            model[0].evaluate(random_pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one : create model and training\n",
    "id = 6\n",
    "print(f'start to train. [id={id}]')\n",
    "models[6] = create_model_v1(id=6, dataset=dataset, epoch=10, verbose=True)\n",
    "print(f'model = {models[6]}')\n",
    "print(f'end to train. [id={id}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #1\n",
    "title = \"history #1\"\n",
    "model_num = 0 # real 1\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #2\n",
    "title = \"history #2\"\n",
    "model_num = 1 # real 2\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #3\n",
    "title = \"history #3\"\n",
    "model_num = 2 # real 3\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #4\n",
    "title = \"history #4\"\n",
    "model_num = 3 # real 4\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #5\n",
    "title = \"history #5\"\n",
    "model_num = 4 # real 5\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #6\n",
    "title = \"history #6\"\n",
    "model_num = 5 # real 6\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3, 6, 7, 11, 12, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_number_set22' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m new1 = flat_data(\u001b[43mprediction_number_set22\u001b[49m)\n\u001b[32m      2\u001b[39m new_dict = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m new1:\n",
      "\u001b[31mNameError\u001b[39m: name 'prediction_number_set22' is not defined"
     ]
    }
   ],
   "source": [
    "new1 = flat_data(prediction_number_set22)\n",
    "new_dict = {}\n",
    "for n in new1:\n",
    "    if n in new_dict:\n",
    "        new_dict[n] += 1\n",
    "    else:\n",
    "        new_dict[n] = 1\n",
    "# print(f'new_dict = {new_dict}')\n",
    "top, all = get_sorted_n_values(new_dict)\n",
    "print(f'all = {all}')\n",
    "print(f'top = {top}')\n",
    "# print(f'new_dict = {new_dict}')\n",
    "bottom, all = get_sorted_n_values(new_dict, is_sort=False)\n",
    "print(f'bottom = {bottom}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set2, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(title='greed_predicted',\n",
    "           data_set=greed_prediction_number_set,\n",
    "           add_val=0, need_sort=True)\n",
    "print(f'greed_prediction_number_set\\n\\t\\t{greed_prediction_number_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when \n",
    "\"\"\"\n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=1 # default = 0.9)\n",
    "epoch=100 # default = 3\n",
    "batch=3 # default = 1\n",
    "model='lstm2' # help = \"lstm or lstm2\")\n",
    "hid_dim = 128\n",
    "\"\"\"\n",
    "for i in range(6):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model={model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pred_set = model2.predict_randomely(trial=1)\n",
    "print(f'prediction_number_set = {random_pred_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1170 : 3·13·28·34·38·42\n",
    "\n",
    "last = [\n",
    "    [6, 8, 37, 40, 41, 44],\n",
    "    [8, 10, 20, 25, 33, 37],\n",
    "    [4, 18, 27, 32, 40, 43],\n",
    "    [2, 8, 10, 31, 33, 35],\n",
    "    [15, 20, 28, 38, 41, 45],\n",
    "    [12, 26, 13, 5, 31, 38]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1171 : [3, 6, 7, 11, 12, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearml",
   "language": "python",
   "name": "clearml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
