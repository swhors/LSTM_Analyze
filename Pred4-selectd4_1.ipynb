{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with LSTM model (v.4.4.1)\n",
    "<p style='text-align: right;'>with selectd4.csv</p>\n",
    "\n",
    "* history\n",
    "  * 2025/05/23 PM06:02 : 3번째 모델의 3번째 데이터를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "from datetime import datetime\n",
    "print(f'restart kernel... {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restart kernel... 2025-05-28 12:00:53.426582\n"
     ]
    }
   ],
   "source": [
    "def restart_kernel():\n",
    "    # Restart the kernet after libraries are loaded.\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f'restart kernel... {datetime.now()}')\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported library. (2025-05-28 13:17:27.631430)\n"
     ]
    }
   ],
   "source": [
    "# load dependacies\n",
    "import os\n",
    "import time\n",
    "import resource\n",
    "from datetime import datetime\n",
    "from lib.globalvar import *\n",
    "from lib.data_loader import DataLoader\n",
    "from lib.small_predict import predict_small, print_predict_small\n",
    "from lib.activation import ActivationOutput, RecurrentActivation\n",
    "from lib.small_predict import build_and_predict, gen_multi_model, save_model, generate_metric\n",
    "from lib.common_env_sets import lstm_units, dense_units, steps, metrics, dropout\n",
    "from lib.common_env_sets import learning_rate, last_lstm_return_sequences\n",
    "from lib.common_env_sets import loss, output_dense_activation, epochs, rand_seed\n",
    "\n",
    "print(f\"imported library. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished to set environemnt. (2025-05-28 13:17:33.083592)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## 모델링 환경 설정\n",
    "##\n",
    "window=1 # default = 1 , help = \"time stamps\"\n",
    "data_dir='./csv/selectd4.csv'\n",
    "    \n",
    "mode='predict' # help = \"back-test or predict\")\n",
    "\n",
    "mode2='sampling' # help = \"greed or sampling\")\n",
    "verb='verbose' # help = \"verbose or not_verb\")\n",
    "    \n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=0.95 # default = 0.9)\n",
    "epoch=20 # default = 3\n",
    "batch=1 # default = 1\n",
    "model_type='lstm4' # help = \"lstm1 or lstm2\")\n",
    "hid_dim = 50\n",
    "from_pos = 0\n",
    "last = [[1, 5, 18, 20, 30, 35],\n",
    "        [7, 9, 24, 40, 42, 44],\n",
    "        [3, 6, 7, 11, 12, 17],\n",
    "        [3, 13, 28, 34, 38, 42],\n",
    "        [5, 12, 24, 29, 32, 42]]\n",
    "\n",
    "print(f\"finished to set environemnt. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/home/swhors/jupyter-workspace/finance/venv/lib/python3.11/site-packages/tensorflow/_api/v2/version/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(f'{tf.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to load data. 2025-05-28 13:17:34.518477\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = {\n",
    "    1: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=0,\n",
    "                  verbose=False\n",
    "                  ),\n",
    "    2: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=300,\n",
    "                  verbose=False\n",
    "                  )\n",
    "    }\n",
    "#print(f'test_X = {dataset_dicts[1].test_X}')\n",
    "print(f'completed to load data. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to set evn for all models. 2025-05-28 13:17:35.716064\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## layers\n",
    "## LSTM Neural 계층 선언\n",
    "###########\n",
    "datasets = [dataset_dicts[1], # 0\n",
    "            dataset_dicts[2], # 1\n",
    "           ]\n",
    "\n",
    "lstm_args = {1: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                          \"dropout\": dropout[0],\n",
    "                          \"steps\": steps[0], # last output elements count\n",
    "                          \"metrics\": metrics[0],\n",
    "                          \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                          \"lstm_units\": lstm_units[0],\n",
    "                          \"dense_units\": dense_units[0],\n",
    "                          \"output_dense_activation\": output_dense_activation[0],\n",
    "                          \"loss\": loss[0],\n",
    "                          \"rand_seed\": rand_seed[0]\n",
    "                          },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 1\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             2: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                          \"dropout\": dropout[0],\n",
    "                          \"steps\": steps[0], # last output elements count\n",
    "                          \"metrics\": metrics[0],\n",
    "                          \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                          \"lstm_units\": lstm_units[1],\n",
    "                          \"dense_units\": dense_units[1],\n",
    "                          \"output_dense_activation\": output_dense_activation[0],\n",
    "                          \"loss\": loss[0],\n",
    "                          \"rand_seed\": rand_seed[0]\n",
    "                          },\n",
    "                 \"train\": {\"epochs\": epochs[1],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 1\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             3: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                          \"dropout\": dropout[0],\n",
    "                          \"steps\": steps[0], # last output elements count\n",
    "                          \"metrics\": metrics[0],\n",
    "                          \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                          \"lstm_units\": lstm_units[1],\n",
    "                          \"dense_units\": dense_units[1],\n",
    "                          \"output_dense_activation\": output_dense_activation[0],\n",
    "                          \"loss\": loss[0],\n",
    "                          \"rand_seed\": rand_seed[1]\n",
    "                          },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 1\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             4: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                          \"dropout\": dropout[1],\n",
    "                          \"steps\": steps[0], # last output elements count\n",
    "                          \"metrics\": metrics[0],\n",
    "                          \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                          \"lstm_units\": lstm_units[2],\n",
    "                          \"dense_units\": dense_units[2],\n",
    "                          \"output_dense_activation\": output_dense_activation[3],\n",
    "                          \"loss\": loss[1],\n",
    "                          \"return_state\": False,\n",
    "                          \"rand_seed\": rand_seed[0] # rand_seed[0]\n",
    "                          },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 3,\n",
    "                           \"steps_per_epoch\": 90 #100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             5: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                          \"dropout\": dropout[1],\n",
    "                          \"steps\": steps[0], # last output elements count\n",
    "                          \"metrics\": metrics[0],\n",
    "                          \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                          \"lstm_units\": lstm_units[3],\n",
    "                          \"dense_units\": dense_units[3],\n",
    "                          \"output_dense_activation\": output_dense_activation[3],\n",
    "                          \"loss\": loss[1],\n",
    "                          \"rand_seed\": rand_seed[0]\n",
    "                          },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 3,\n",
    "                           \"steps_per_epoch\": 100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             6: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                          \"dropout\": dropout[1],\n",
    "                          \"steps\": steps[0], # last output elements count\n",
    "                          \"metrics\": metrics[0],\n",
    "                          \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                          \"lstm_units\": lstm_units[5],\n",
    "                          \"dense_units\": dense_units[4],\n",
    "                          \"output_dense_activation\": output_dense_activation[3],\n",
    "                          \"loss\": loss[1],\n",
    "                          \"return_state\": False,\n",
    "                          \"lstm_model\": \"Bidirectional\",\n",
    "                          \"rand_seed\": rand_seed[0] # rand_seed[0]\n",
    "                          },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 3,\n",
    "                           \"steps_per_epoch\": 90 #100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 }\n",
    "             }\n",
    "\n",
    "print(f'completed to set evn for all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "working model_version = 16  2025-05-28 13:45:30.786815\n",
      "********************\n",
      "start to train all models. 2025-05-28 13:45:30.787124\n",
      "1's training. status=start 2025-05-28 13:45:30.787145\n",
      "1's training. status=end 2025-05-28 13:46:29.418047\n",
      "2's training. status=start 2025-05-28 13:46:29.418143\n",
      "2's training. status=end 2025-05-28 13:46:49.439612\n",
      "3's training. status=start 2025-05-28 13:46:49.439709\n",
      "3's training. status=end 2025-05-28 13:47:34.962373\n",
      "4's training. status=start 2025-05-28 13:47:34.962472\n",
      "4's training. status=end 2025-05-28 13:48:16.882164\n",
      "5's training. status=start 2025-05-28 13:48:16.882268\n",
      "5's training. status=end 2025-05-28 13:48:52.400099\n",
      "6's training. status=start 2025-05-28 13:48:52.400198\n",
      "6's training. status=end 2025-05-28 13:49:11.085235\n",
      "completed to train all models. 2025-05-28 13:49:11.085332\n",
      "train to create model(16). 2025-05-28 13:49:11.085345\n",
      "CPU 시간: 1684.304624 초\n",
      "메모리 사용량: 2525104 KB\n",
      "********************\n",
      "working model_version = 17  2025-05-28 13:49:58.378937\n",
      "********************\n",
      "start to train all models. 2025-05-28 13:49:58.378974\n",
      "1's training. status=start 2025-05-28 13:49:58.378991\n",
      "1's training. status=end 2025-05-28 13:50:56.903587\n",
      "2's training. status=start 2025-05-28 13:50:56.903681\n",
      "2's training. status=end 2025-05-28 13:51:16.319599\n",
      "3's training. status=start 2025-05-28 13:51:16.319700\n",
      "3's training. status=end 2025-05-28 13:52:01.893797\n",
      "4's training. status=start 2025-05-28 13:52:01.893893\n",
      "4's training. status=end 2025-05-28 13:52:43.838106\n",
      "5's training. status=start 2025-05-28 13:52:43.838224\n",
      "5's training. status=end 2025-05-28 13:53:17.349911\n",
      "6's training. status=start 2025-05-28 13:53:17.350010\n",
      "6's training. status=end 2025-05-28 13:53:35.409364\n",
      "completed to train all models. 2025-05-28 13:53:35.409650\n",
      "train to create model(17). 2025-05-28 13:53:35.409668\n",
      "CPU 시간: 1967.817839 초\n",
      "메모리 사용량: 2870640 KB\n",
      "********************\n",
      "working model_version = 18  2025-05-28 13:54:26.705700\n",
      "********************\n",
      "start to train all models. 2025-05-28 13:54:26.705736\n",
      "1's training. status=start 2025-05-28 13:54:26.705753\n",
      "1's training. status=end 2025-05-28 13:55:25.814963\n",
      "2's training. status=start 2025-05-28 13:55:25.815067\n",
      "2's training. status=end 2025-05-28 13:55:45.415576\n",
      "3's training. status=start 2025-05-28 13:55:45.415674\n",
      "3's training. status=end 2025-05-28 13:56:30.746700\n",
      "4's training. status=start 2025-05-28 13:56:30.746815\n",
      "4's training. status=end 2025-05-28 13:57:12.628961\n",
      "5's training. status=start 2025-05-28 13:57:12.629060\n",
      "5's training. status=end 2025-05-28 13:57:45.597305\n",
      "6's training. status=start 2025-05-28 13:57:45.597400\n",
      "6's training. status=end 2025-05-28 13:58:03.610786\n",
      "completed to train all models. 2025-05-28 13:58:03.610892\n",
      "train to create model(18). 2025-05-28 13:58:03.610909\n",
      "CPU 시간: 2247.653713 초\n",
      "메모리 사용량: 3204256 KB\n",
      "********************\n",
      "working model_version = 19  2025-05-28 13:58:53.641299\n",
      "********************\n",
      "start to train all models. 2025-05-28 13:58:53.641337\n",
      "1's training. status=start 2025-05-28 13:58:53.641353\n",
      "1's training. status=end 2025-05-28 13:59:52.053129\n",
      "2's training. status=start 2025-05-28 13:59:52.053225\n",
      "2's training. status=end 2025-05-28 14:00:12.504713\n",
      "3's training. status=start 2025-05-28 14:00:12.504815\n",
      "3's training. status=end 2025-05-28 14:00:58.459482\n",
      "4's training. status=start 2025-05-28 14:00:58.459583\n",
      "4's training. status=end 2025-05-28 14:01:44.129864\n",
      "5's training. status=start 2025-05-28 14:01:44.129969\n",
      "5's training. status=end 2025-05-28 14:02:17.581043\n",
      "6's training. status=start 2025-05-28 14:02:17.581144\n",
      "6's training. status=end 2025-05-28 14:02:35.614116\n",
      "completed to train all models. 2025-05-28 14:02:35.614398\n",
      "train to create model(19). 2025-05-28 14:02:35.614414\n",
      "CPU 시간: 2531.176947 초\n",
      "메모리 사용량: 3313648 KB\n",
      "********************\n",
      "working model_version = 20  2025-05-28 14:03:23.156627\n",
      "********************\n",
      "start to train all models. 2025-05-28 14:03:23.156655\n",
      "1's training. status=start 2025-05-28 14:03:23.156666\n",
      "1's training. status=end 2025-05-28 14:04:21.905516\n",
      "2's training. status=start 2025-05-28 14:04:21.905887\n",
      "2's training. status=end 2025-05-28 14:04:42.487198\n",
      "3's training. status=start 2025-05-28 14:04:42.487295\n",
      "3's training. status=end 2025-05-28 14:05:29.301788\n",
      "4's training. status=start 2025-05-28 14:05:29.301884\n",
      "4's training. status=end 2025-05-28 14:06:11.159386\n",
      "5's training. status=start 2025-05-28 14:06:11.159486\n",
      "5's training. status=end 2025-05-28 14:06:43.987309\n",
      "6's training. status=start 2025-05-28 14:06:43.987407\n",
      "6's training. status=end 2025-05-28 14:07:02.056414\n",
      "completed to train all models. 2025-05-28 14:07:02.056515\n",
      "train to create model(20). 2025-05-28 14:07:02.056527\n",
      "CPU 시간: 2815.917497 초\n",
      "메모리 사용량: 3656320 KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "model_version_from = 16\n",
    "model_version_end = 20\n",
    "args = {'test_id': 'P4_4_1_1_1',\n",
    "        'version': model_version_from,\n",
    "        'write_to_db': True,\n",
    "        'last': last,\n",
    "        'mode2': mode2,\n",
    "        'gen_num': 5,\n",
    "        'round_limit': 40,\n",
    "        'db_file_name': \"./db/metrics.db\"\n",
    "       }\n",
    "generate_metric(args=args, from_version=model_version_from, to_version=model_version_end, lstm_args=lstm_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_model_info = False\n",
    "if view_model_info:\n",
    "    for i in range(MAX_MODEL_CNT):\n",
    "        print(models[i][0].model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : save model\n",
    "for model in models:\n",
    "    if model is not None:\n",
    "        model[0].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "finance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
