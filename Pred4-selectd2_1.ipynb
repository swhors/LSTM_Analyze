{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with LSTM model\n",
    "<p style='text-align: right;'>with selectd1.csv</p>\n",
    "\n",
    "* history\n",
    "  * 2025/05/14 PM06:56 : 모델에 대한 기능을 공통화 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_kernel():\n",
    "    # Restart the kernet after libraries are loaded.\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f'restart kernel... {datetime.now()}')\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "from datetime import datetime\n",
    "print(f'restart kernel... {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restart kernel... 2025-05-15 17:06:07.360561\n"
     ]
    }
   ],
   "source": [
    "restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 15:32:48.755510: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported library. (2025-05-16 15:32:50.463520)\n"
     ]
    }
   ],
   "source": [
    "# load dependacies\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "from globalvar import *\n",
    "from data import DataLoader\n",
    "from model1 import PredictLSTM1\n",
    "from model2 import PredictLSTM2\n",
    "from model3 import PredictLSTM3\n",
    "from model4 import PredictLSTM4\n",
    "\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util_pred import print_data\n",
    "from util_pred import flat_data_with_sum, flat_data, get_frequency\n",
    "from util_pred import save_model, import_mode\n",
    "from util_pred import get_random_in_list\n",
    "from util_pred import print_data_with_sort\n",
    "from util_pred import get_sorted_n_values\n",
    "from util_pred import dict_key_count\n",
    "from util_pred import print_list\n",
    "from util_pred import print_dict_list\n",
    "from util_pred import print_title\n",
    "from activation import ActivationOutput, RecurrentActivation\n",
    "from datetime import datetime\n",
    "\n",
    "from operate import create_model, create_model_v1, get_predicted\n",
    "\n",
    "print(f\"imported library. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished to set environemnt. (2025-05-16 16:53:50.454078)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## 모델링 환경 설정\n",
    "##\n",
    "window=1 # default = 1 , help = \"time stamps\"\n",
    "data_dir='./selectd2.csv'\n",
    "    \n",
    "mode='predict' # help = \"back-test or predict\")\n",
    "mode2='sampling' # help = \"greed or sampling\")\n",
    "verb='verbose' # help = \"verbose or not_verb\")\n",
    "    \n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=1 # default = 0.9)\n",
    "epoch=20 # default = 3\n",
    "batch=1 # default = 1\n",
    "model_type='lstm4' # help = \"lstm1 or lstm2\")\n",
    "hid_dim = 50\n",
    "from_pos = 0\n",
    "last = [[3, 6, 7, 11, 12, 17],\n",
    "        [3, 13, 28, 34, 38, 42],\n",
    "        [5, 12, 24, 29, 32, 42]]\n",
    "print(f\"finished to set environemnt. ({datetime.now()})\")\n",
    "MAX_MODEL_CNT = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader.preproc_csv origin = 570, [[ 601    2   16 ...   31   34   35]\n",
      " [ 602   13   14 ...   27   30   38]\n",
      " [ 603    2   19 ...   26   27   43]\n",
      " ...\n",
      " [1168    9   21 ...   30   33   37]\n",
      " [1169    5   12 ...   26   39   42]\n",
      " [1170    3   13 ...   34   38   42]]\n",
      "rDataLoader.preproc_csv aw_np_proc = 570, [[16 19 31 34 35]\n",
      " [14 22 27 30 38]\n",
      " [19 25 26 27 43]\n",
      " ...\n",
      " [21 24 30 33 37]\n",
      " [12 24 26 39 42]\n",
      " [13 28 34 38 42]]\n",
      "DataLoader.preproc_csv origin = 570, [[ 601    2   16 ...   31   34   35]\n",
      " [ 602   13   14 ...   27   30   38]\n",
      " [ 603    2   19 ...   26   27   43]\n",
      " ...\n",
      " [1168    9   21 ...   30   33   37]\n",
      " [1169    5   12 ...   26   39   42]\n",
      " [1170    3   13 ...   34   38   42]]\n",
      "rDataLoader.preproc_csv aw_np_proc = 570, [[16 19 31 34 35]\n",
      " [14 22 27 30 38]\n",
      " [19 25 26 27 43]\n",
      " ...\n",
      " [21 24 30 33 37]\n",
      " [12 24 26 39 42]\n",
      " [13 28 34 38 42]]\n",
      "DataLoader.preproc_csv origin = 570, [[ 601    2   16 ...   31   34   35]\n",
      " [ 602   13   14 ...   27   30   38]\n",
      " [ 603    2   19 ...   26   27   43]\n",
      " ...\n",
      " [1168    9   21 ...   30   33   37]\n",
      " [1169    5   12 ...   26   39   42]\n",
      " [1170    3   13 ...   34   38   42]]\n",
      "rDataLoader.preproc_csv aw_np_proc = 270, [[18 20 23 30 34]\n",
      " [19 23 24 36 39]\n",
      " [15 16 21 22 28]\n",
      " ...\n",
      " [21 24 30 33 37]\n",
      " [12 24 26 39 42]\n",
      " [13 28 34 38 42]]\n",
      "completed to load data. 2025-05-16 15:41:59.589916\n"
     ]
    }
   ],
   "source": [
    "# data prepare and set base model\n",
    "dataset = DataLoader(data_dir=data_dir,\n",
    "                     training_length=training_length,\n",
    "                     window_prev=window,\n",
    "                     mode=mode,\n",
    "                     from_pos=from_pos\n",
    "                    )\n",
    "\n",
    "dataset_dicts = {\n",
    "    1: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=0\n",
    "                  ),\n",
    "    2: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=300\n",
    "                  )\n",
    "    }\n",
    "print(f'completed to load data. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to set evn for all models. 2025-05-16 16:55:52.725467\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## layers\n",
    "## LSTM Neural 계층 선언\n",
    "###########\n",
    "\"\"\"\n",
    "Activation (Output):\n",
    "    linear: No activation, output is directly passed through.\n",
    "    relu: Rectified Linear Unit, max(x, 0).\n",
    "    sigmoid: Sigmoid function, output between 0 and 1.\n",
    "    tanh: Hyperbolic tangent, output between -1 and 1.\n",
    "    softmax: Normalizes output to a probability distribution.\n",
    "    elu: Exponential Linear Unit.\n",
    "    selu: Scaled Exponential Linear Unit.\n",
    "\n",
    "Recurrent Activation:\n",
    "    sigmoid: Commonly used for gates in LSTM.\n",
    "    hard_sigmoid: A faster, less computationally expensive version of sigmoid.\n",
    "    tanh: Can be used, but sigmoid is more typical for gates.\n",
    "\"\"\"\n",
    "lstm_layers = {\n",
    "    4: [LSTM(hid_dim,\n",
    "             activation=ActivationOutput.selu.name,\n",
    "             return_sequences=True),\n",
    "        LSTM(hid_dim,\n",
    "             return_sequences=True,\n",
    "             activation=ActivationOutput.selu.name),\n",
    "        LSTM(hid_dim,\n",
    "             return_sequences=True,\n",
    "             activation=ActivationOutput.sigmoid.name),\n",
    "        LSTM(hid_dim,\n",
    "             return_sequences=False,\n",
    "             activation=ActivationOutput.elu.name,\n",
    "             recurrent_activation=\"hard_sigmoid\")],\n",
    "    }\n",
    "\n",
    "simple_lstm_layer = [LSTM(hid_dim,\n",
    "                     activation=ActivationOutput.elu.name)]\n",
    "\n",
    "dense_layers = {0: [Dense(45, activation='softmax'),\n",
    "                    Dense(45, activation='sigmoid')],\n",
    "                7: [Dense(45, activation='softmax')]\n",
    "               }\n",
    "simple_dense_layer = [Dense(45, activation='softmax')]\n",
    "\n",
    "layers = [\n",
    "    lstm_layers[4] + dense_layers[7], # 4\n",
    "    lstm_layers[4] + dense_layers[0], # 5\n",
    "    ]\n",
    "\n",
    "datasets = [dataset_dicts[1], # 4\n",
    "            dataset_dicts[2], # 5\n",
    "           ]\n",
    "\n",
    "epochs = [20, 10]\n",
    "\n",
    "models = [None for i in range(MAX_MODEL_CNT)]\n",
    "#matched_cnts = [0 for i in range(MAX_MODEL_CNT)]\n",
    "#selected_fives = [None for i in range(MAX_MODEL_CNT)]\n",
    "#matched_list = [None for i in range(MAX_MODEL_CNT)]\n",
    "#predicted_all = [None for i in range(MAX_MODEL_CNT)]\n",
    "\n",
    "matched_cnts = {}\n",
    "selected_fives = {}\n",
    "matched_list = {}\n",
    "predicted_all = {}\n",
    "\n",
    "print(f'completed to set evn for all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to train all models. 2025-05-16 16:56:08.143899\n",
      "1's training. status=start 2025-05-16 16:56:08.144059\n",
      "1's training. status=end 2025-05-16 16:56:40.976720\n",
      "2's training. status=start 2025-05-16 16:56:40.976817\n",
      "2's training. status=end 2025-05-16 16:57:42.146504\n",
      "3's training. status=start 2025-05-16 16:57:42.146606\n",
      "3's training. status=end 2025-05-16 16:57:56.956036\n",
      "4's training. status=start 2025-05-16 16:57:56.956146\n",
      "4's training. status=end 2025-05-16 16:58:22.574932\n",
      "5's training. status=start 2025-05-16 16:58:22.575032\n",
      "5's training. status=end 2025-05-16 16:58:31.744049\n",
      "6's training. status=start 2025-05-16 16:58:31.744170\n",
      "6's training. status=end 2025-05-16 16:58:46.533942\n",
      "completed to train all models. 2025-05-16 16:58:46.534216\n"
     ]
    }
   ],
   "source": [
    "# all : create model and training\n",
    "print(f'start to train all models. {datetime.now()}')\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    print(f'{i+1}\\'s training. status=start {datetime.now()}')\n",
    "    model = create_model(id=i,\n",
    "                         model_type=\"lstm4\",\n",
    "                         layers=layers[i],\n",
    "                         dataset=datasets[i],\n",
    "                         hid_dim=hid_dim,\n",
    "                         epoch=epochs[i],\n",
    "                         verbose=False\n",
    "                        )\n",
    "    models[i] = (model, layers[i])\n",
    "    print(f'{i+1}\\'s training. status=end {datetime.now()}')\n",
    "print(f'completed to train all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check to create model. 2025-05-16 16:59:31.699518\n"
     ]
    }
   ],
   "source": [
    "print(f'check to create model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : predict #1\n",
    "greed_prediction = [None for i in range(MAX_MODEL_CNT)]\n",
    "random_pred = [None for i in range(MAX_MODEL_CNT)]\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    greed_prediction[i] = models[i][0].predict_numbers(\"greed\", trial=1)\n",
    "    random_pred[i] = models[i][0].predict_randomely(trial=1)\n",
    "    print(f'{i+1}\\'s greed_prediction = {greed_prediction[i]}')\n",
    "    print(f'{i+1}\\'s random_pred = {random_pred[i]}')\n",
    "print(f'comleted to predict model. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_model(model_cnt=MAX_MODEL_CNT):\n",
    "    matched_cnts = [0 for i in range(MAX_MODEL_CNT)]\n",
    "    selected_fives = [None for i in range(MAX_MODEL_CNT)]\n",
    "    matched_list = [None for i in range(MAX_MODEL_CNT)]\n",
    "    predicted_all = [None for i in range(MAX_MODEL_CNT)]\n",
    "    for i in range(MAX_MODEL_CNT):\n",
    "        title = f\"history #{i+1}\"\n",
    "        if models[i] is not None:\n",
    "            models[i][0].verb = \"None\"\n",
    "            matched_cnts[i], \\\n",
    "            selected_fives[i], \\\n",
    "            matched_list[i], \\\n",
    "            predicted_all[i] = get_predicted(\n",
    "                title=title,\n",
    "                model=models[i][0],\n",
    "                mode=mode2,\n",
    "                use_pre=False,\n",
    "                last=last,\n",
    "                verbose=False,\n",
    "                trial=5\n",
    "                )\n",
    "    return matched_cnts, selected_fives, matched_list, predicted_all\n",
    "\n",
    "\n",
    "def repeat_predict_all_model(trial=1, model_cnt=MAX_MODEL_CNT):\n",
    "    \"\"\" repeat_predict_all_model \"\"\"\n",
    "    matched_cnts = {}\n",
    "    selected_fives = {}\n",
    "    matched_list = {}\n",
    "    predicted_all = {}\n",
    "    for t in range(trial):\n",
    "        matched_cnts[t], \\\n",
    "        selected_fives[t], \\\n",
    "        matched_list[t], \\\n",
    "        predicted_all[t] = predict_all_model(model_cnt)\n",
    "    return matched_cnts, selected_fives, matched_list, predicted_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_cnts, selected_fives, matched_list, predicted_all = repeat_predict_all_model(trial=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_cnts)\n",
    "print(matched_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def listinlist_2_strinlist(list_in_list):\n",
    "    \"\"\" listinlist_2_strinlist \"\"\"\n",
    "    str_in_list = []\n",
    "    for l in list_in_list:\n",
    "        str_in_list.append(\",\".join(l))\n",
    "    return str_in_list      \n",
    "\n",
    "\n",
    "def change_matched_info(matched_count, matched_list):\n",
    "    counts = {}\n",
    "    cnt = 1\n",
    "    for c in matched_count:\n",
    "        counts[cnt] = \",\".join([ str(i) for i in c])\n",
    "        cnt += 1\n",
    "    cnt = 1\n",
    "    datas = {}\n",
    "    for d in matched_list:\n",
    "        datas[cnt] = d\n",
    "        cnt += 1\n",
    "    return counts, datas\n",
    "\n",
    "def write_json(trial, matched_count, matched_list, append=False):\n",
    "    suffix = datetime.now().strftime('%y%m%d_%H')\n",
    "    file_name = f\"matched_{suffix}.json\"\n",
    "    matched_dict = {}\n",
    "    if append:\n",
    "        if os.path.isfile(file_name):\n",
    "            with open(file_name, \"r\") as file:\n",
    "                matched_dict = json.load(file)\n",
    "                file.close()\n",
    "    counts, datas = change_matched_info(matched_count, matched_list)\n",
    "    if len(counts) > 0 and len(datas) > 0:\n",
    "        matched_dict[trial] = {}\n",
    "        matched_dict[trial][\"counts\"] =  counts\n",
    "        matched_dict[trial][\"datas\"] = datas\n",
    "        print(f'matched_dict = {matched_dict}')\n",
    "        with open(file_name, \"w\") as file:\n",
    "            json.dump(matched_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all with trial : print predicted\n",
    "write_json(trial = 3, matched_count=matched_cnts, matched_list=matched_list, append=True)\n",
    "print_dict_list(title=\"matched_cnt\", datas=matched_cnts)\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    print_list(title=f\"matched_list[{i+1}]\", datas=matched_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4시 40분 경 데이터\n",
    "| 회차 | 3이상 ||| 0이 없음 |\n",
    "| -- | -- | -- | -- | -- |\n",
    "|  1 | N ||| N |\n",
    "|  2 | 4, 5 ||| 3 |\n",
    "|  3 | N ||| 3 |\n",
    "|  4 | 2 ||| 5 |\n",
    "|  5 | 4 ||| 1, 6 |\n",
    "|  6 | 5 ||| N |\n",
    "|  7 | N ||| 4 |\n",
    "|  8 | N ||| N |\n",
    "|  9 | 2 ||| N |\n",
    "| 10 | 6 ||| 2 |\n",
    "| 11 | N ||| 2 |\n",
    "| 12 | **2** ||| **2**, 4 |\n",
    "| 13 | 4 ||| N |\n",
    "| 14 | 5 ||| N |\n",
    "| 15 | 1*, 6 ||| 3 |\n",
    "| 16 | 5* ||| N |\n",
    "| 17 | N ||| 6 |\n",
    "| 18 | N ||| N |\n",
    "| 19 | 2 ||| 5 |\n",
    "| 20 | N ||| N |\n",
    "||||||\n",
    "| 21 | N ||| N |\n",
    "| 22 | N ||| 2 |\n",
    "| 23 | 3 ||| N |\n",
    "| 24 | N ||| N |\n",
    "| 25 | 2 ||| N |\n",
    "| 26 | N ||| N |\n",
    "| 27 | N ||| N |\n",
    "| 28 | 3 ||| 5 |\n",
    "| 29 | N ||| 2 |\n",
    "| 30 | N ||| N |\n",
    "| 31 | **3** ||| **3** |\n",
    "| 32 | N ||| N |\n",
    "| 33 | N ||| 3, 5 |\n",
    "| 34 | 6 ||| N |\n",
    "| 35 | N ||| N |\n",
    "| 36 | N ||| N |\n",
    "| 37 | N ||| N |\n",
    "| 38 | 1, 2 ||| N |\n",
    "| 39 | N ||| 6 |\n",
    "| 40 | **5** ||| **5** |\n",
    "| 41 | 6 ||| N |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "predicted time : 2025-05-16 17:12:59.484490\n"
     ]
    }
   ],
   "source": [
    "# all (SMALL): predict #2\n",
    "matched_cnts_small = [0 for i in range(MAX_MODEL_CNT)]\n",
    "selected_fives_small = [None for i in range(MAX_MODEL_CNT)]\n",
    "matched_list_small = [None for i in range(MAX_MODEL_CNT)]\n",
    "predicted_all_small = [None for i in range(MAX_MODEL_CNT)]\n",
    "\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    title = f\"history #{i+1}\"\n",
    "    model_num = i\n",
    "    if models[model_num] is None:\n",
    "        print(f\"model #{model_num+1} is None\")\n",
    "    else:\n",
    "        models[model_num][0].verb = \"None\"\n",
    "        matched_cnts_small[model_num], \\\n",
    "        selected_fives_small[model_num], \\\n",
    "        matched_list_small[model_num], \\\n",
    "        predicted_all_small[model_num] = get_predicted(\n",
    "            title=title,\n",
    "            model=models[model_num][0],\n",
    "            mode=mode2,\n",
    "            use_pre=False,\n",
    "            last=last,\n",
    "            verbose=False,\n",
    "            trial=5\n",
    "        )\n",
    "print(f'predicted time : {datetime.now()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 회차 | 3이상 ||| 0이 없음 |\n",
    "| -- | -- | -- | -- | -- |\n",
    "|  1 | N ||| 3 |\n",
    "|  2 | N ||| 2 |\n",
    "|  3 | N ||| 5 |\n",
    "|  4 | N ||| 4, 6 |\n",
    "|  5 | 1 ||| 3 |\n",
    "|  6 | 4, 6 ||| 3 |\n",
    "|  7 | N ||| N |\n",
    "|  8 | 3 ||| N |\n",
    "|  9 | 4 ||| N |\n",
    "| 10 | N ||| N |\n",
    "| 11 | 3 ||| N |\n",
    "| 12 | N ||| N |\n",
    "| 13 | 4 ||| N |\n",
    "| 14 | 1, 5, 6 ||| N |\n",
    "| 15 | N ||| N |\n",
    "| 16 | N ||| 1 |\n",
    "| 17 | 4 ||| N |\n",
    "| 18 | 4, 6 ||| 5 |\n",
    "| 19 | 1, 5 ||| N |\n",
    "| 20 | 1, 5, 5, 5 ||| 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{14:6, 13:8, 12:4, _11:10_, 10:3, 9:1, 8:6, 7:5, 6:4, 5:9, 4:4, 3:7, 2:7, 1:4}\n",
    "## 4시 40분경 데이터\n",
    "- {2: 6, 5: 5, 6: 4, 4: 3, 3: 3, 1: 2}\n",
    "- {6: 4, 5: 5, 4: 3, 3: 3, 2: 6, 1: 2}\n",
    "\n",
    "## 5시 20분경 데이터\n",
    "- {4: 5, 5: 5, 1: 4, 6: 3, 3: 2}\n",
    "- {6: 3, 5: 5, 4: 5, 3: 2, 1: 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print time : 2025-05-16 17:13:01.893074\n",
      "matched_cnt\n",
      "\t1's : {1: 3, 2: 1, 3: 1}\n",
      "\t2's : {0: 1, 1: 3, 2: 1}\n",
      "\t3's : {0: 3, 1: 2}\n",
      "\t4's : {0: 1, 1: 3, 2: 1}\n",
      "\t5's : {0: 1, 2: 1, 3: 2, 4: 1}\n",
      "\t6's : {0: 2, 1: 1, 2: 2}\n",
      "matched_list[1]\n",
      "\t([6, 15, 27, 29, 36, 42], [6])\n",
      "\t([4, 16, 18, 39, 11, 6], [6, 11])\n",
      "\t([1, 2, 6, 13, 19, 25], [6])\n",
      "\t([1, 3, 29, 33, 36, 38], [3])\n",
      "\t([3, 6, 7, 9, 38, 41], [3, 6, 7])\n",
      "matched_list[2]\n",
      "\t([3, 5, 21, 34, 40, 45], [3])\n",
      "\t([2, 4, 5, 16, 36, 37], [])\n",
      "\t([1, 43, 3, 13, 40, 4], [3])\n",
      "\t([6, 7, 23, 27, 34, 36], [6, 7])\n",
      "\t([11, 16, 24, 33, 43, 45], [11])\n",
      "matched_list[3]\n",
      "\t([11, 14, 25, 28, 30, 43], [11])\n",
      "\t([5, 10, 16, 18, 26, 42], [])\n",
      "\t([10, 37, 8, 22, 40, 34], [])\n",
      "\t([4, 12, 22, 30, 38, 42], [12])\n",
      "\t([31, 4, 30, 16, 33, 23], [])\n",
      "matched_list[4]\n",
      "\t([41, 21, 4, 11, 43, 31], [11])\n",
      "\t([5, 8, 17, 21, 23, 35], [17])\n",
      "\t([16, 18, 29, 38, 41, 33], [])\n",
      "\t([5, 7, 12, 32, 33, 38], [7, 12])\n",
      "\t([14, 17, 20, 24, 36, 45], [17])\n",
      "matched_list[5]\n",
      "\t([6, 7, 11, 17, 23, 42], [6, 7, 11, 17])\n",
      "\t([18, 21, 22, 25, 26, 40], [])\n",
      "\t([28, 12, 6, 37, 9, 7], [6, 7, 12])\n",
      "\t([20, 6, 11, 5, 7, 38], [6, 7, 11])\n",
      "\t([3, 11, 15, 36, 37, 40], [3, 11])\n",
      "matched_list[6]\n",
      "\t([8, 20, 21, 26, 36, 37], [])\n",
      "\t([25, 16, 3, 33, 1, 6], [3, 6])\n",
      "\t([3, 4, 12, 16, 22, 32], [3, 12])\n",
      "\t([10, 20, 24, 38, 41, 42], [])\n",
      "\t([12, 26, 31, 35, 44, 45], [12])\n"
     ]
    }
   ],
   "source": [
    "# all (SMALL): print predicted\n",
    "print(f'print time : {datetime.now()}')\n",
    "#write_json(trial = 3, matched_count=matched_cnts_small, matched_list=matched_list_small, append=True)\n",
    "print_dict_list(title=\"matched_cnt\", datas=matched_cnts_small)\n",
    "for i in range(MAX_MODEL_CNT):\n",
    "    print_list(title=f\"matched_list[{i+1}]\", datas=matched_list_small[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : save model\n",
    "for model in models:\n",
    "    if model is not None:\n",
    "        model[0].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : model info\n",
    "#################\n",
    "# model info\n",
    "#################\n",
    "for model in models:\n",
    "    if model is not None:\n",
    "        print(f'model:\\n\\t{model[0].model.summary()}')\n",
    "        print(f'layer:\\n\\t{model[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all : model test\n",
    "mode = \"back-test\"\n",
    "if mode == 'back-test':\n",
    "    for model in models:\n",
    "        if model is not None:\n",
    "            greed_prediction_number_set = model[0].predict_numbers(\"greed\", trial=1)\n",
    "            random_pred_set = model[0].predict_randomely(trial=1)\n",
    "            model[0].evaluate(greed_prediction_number_set)\n",
    "            print(\"---------Random baseline-------------\")\n",
    "            model[0].evaluate(random_pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one : create model and training\n",
    "id = 6\n",
    "print(f'start to train. [id={id}]')\n",
    "models[6] = create_model_v1(id=6, dataset=dataset, epoch=10, verbose=True)\n",
    "print(f'model = {models[6]}')\n",
    "print(f'end to train. [id={id}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #1\n",
    "title = \"history #1\"\n",
    "model_num = 0 # real 1\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #2\n",
    "title = \"history #2\"\n",
    "model_num = 1 # real 2\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #3\n",
    "title = \"history #3\"\n",
    "model_num = 2 # real 3\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #4\n",
    "title = \"history #4\"\n",
    "model_num = 3 # real 4\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #5\n",
    "title = \"history #5\"\n",
    "model_num = 4 # real 5\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict #6\n",
    "title = \"history #6\"\n",
    "model_num = 5 # real 6\n",
    "if models[model_num] is None:\n",
    "    print(f\"model #{model_num+1} is None\")\n",
    "else:\n",
    "    models[model_num][0].verb = \"None\"\n",
    "    matched_cnts[model_num], \\\n",
    "    selected_fives[model_num], \\\n",
    "    matched_list[model_num], \\\n",
    "    predicted_all[model_num] = get_predicted(\n",
    "        title=title,\n",
    "        model=models[model_num][0],\n",
    "        mode=mode2,\n",
    "        use_pre=False,\n",
    "        last=last,\n",
    "        verbose=True,\n",
    "        trial=10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3, 6, 7, 11, 12, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_number_set22' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m new1 = flat_data(\u001b[43mprediction_number_set22\u001b[49m)\n\u001b[32m      2\u001b[39m new_dict = {}\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m new1:\n",
      "\u001b[31mNameError\u001b[39m: name 'prediction_number_set22' is not defined"
     ]
    }
   ],
   "source": [
    "new1 = flat_data(prediction_number_set22)\n",
    "new_dict = {}\n",
    "for n in new1:\n",
    "    if n in new_dict:\n",
    "        new_dict[n] += 1\n",
    "    else:\n",
    "        new_dict[n] = 1\n",
    "# print(f'new_dict = {new_dict}')\n",
    "top, all = get_sorted_n_values(new_dict)\n",
    "print(f'all = {all}')\n",
    "print(f'top = {top}')\n",
    "# print(f'new_dict = {new_dict}')\n",
    "bottom, all = get_sorted_n_values(new_dict, is_sort=False)\n",
    "print(f'bottom = {bottom}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set2, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_data(title='greed_predicted',\n",
    "           data_set=greed_prediction_number_set,\n",
    "           add_val=0, need_sort=True)\n",
    "print(f'greed_prediction_number_set\\n\\t\\t{greed_prediction_number_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when \n",
    "\"\"\"\n",
    "trial=20 # help = \"how much trials to generate\")\n",
    "training_length=1 # default = 0.9)\n",
    "epoch=100 # default = 3\n",
    "batch=3 # default = 1\n",
    "model='lstm2' # help = \"lstm or lstm2\")\n",
    "hid_dim = 128\n",
    "\"\"\"\n",
    "for i in range(6):\n",
    "    print(f'{i} : {get_random_in_list(prediction_number_set, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'model={model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pred_set = model2.predict_randomely(trial=1)\n",
    "print(f'prediction_number_set = {random_pred_set}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1170 : 3·13·28·34·38·42\n",
    "\n",
    "last = [\n",
    "    [6, 8, 37, 40, 41, 44],\n",
    "    [8, 10, 20, 25, 33, 37],\n",
    "    [4, 18, 27, 32, 40, 43],\n",
    "    [2, 8, 10, 31, 33, 35],\n",
    "    [15, 20, 28, 38, 41, 45],\n",
    "    [12, 26, 13, 5, 31, 38]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1171 : [3, 6, 7, 11, 12, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clearml",
   "language": "python",
   "name": "clearml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
