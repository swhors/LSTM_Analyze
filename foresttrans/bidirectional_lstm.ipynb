{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1102e40b-8e3c-47f2-b80f-33c64d73f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train =  [[391 921 679 323 976 882 717 458 542 828]\n",
      " [323 284 770 616 889 719 225 351 811 354]\n",
      " [816 911 587 269   8 222 219 694 147 147]\n",
      " [951 422 402 472 906 922 425 772 120  55]\n",
      " [326 699 374 499 324 876 715 256 869 277]\n",
      " [219 139  56 605 944 768  29 673 538 869]\n",
      " [144 552 403  42 218 942 562 740 459 528]\n",
      " [631 705 677  72 848 871  45 299 350 550]\n",
      " [503 364 592 198 619 264 275 295  83   8]\n",
      " [249 158 112 191 738 763 839 925 316 308]\n",
      " [299 470 299 369 647 847 407 135  73 120]\n",
      " [954 254 663 393 542 152 561 893 184 577]\n",
      " [339 674 481 639 891 161 108 104 238 492]\n",
      " [565 725 326 870 694 932 254 338 397 965]\n",
      " [215 395 670 818 393  82 213 200  79 539]\n",
      " [126 489 135 341 770 572 292 683 171 724]\n",
      " [210 470 123 959 127 589 204 662 375 524]\n",
      " [ 80 729 389 694 365 451 929 714 643 738]\n",
      " [117  43  92 134 758 224 252 257 269 605]\n",
      " [177 317 601 685 101 766 769 897 287 828]\n",
      " [928 112 482 549 410 625 424 601 795  22]\n",
      " [347 495 540 178 845 275  13 796 687 388]\n",
      " [379 313 510 448 168 330 323 851  16 580]\n",
      " [820 838 545 873 400 367 965   6 693 552]\n",
      " [350  95 347 790 539  59 391 583  68 190]\n",
      " [232 889 614 992 527 915 406 431 367 320]\n",
      " [792 305 456  19 471  95 133 823  46 622]\n",
      " [441 509 855 222 198 501 709 799 419 252]\n",
      " [ 67  99 669 396 352 151 417  69 307  97]\n",
      " [ 87 265 330 752 601 478 100 219 823 748]\n",
      " [256 831 167 403 126 807 112 396 264 959]\n",
      " [118 868 959 193 772  38 703 921 886 684]\n",
      " [462 678 969 301 537 534 807 876 941 492]\n",
      " [507 801 451 575 876 319 392 340 518 330]\n",
      " [ 92 733 582 646 255 965 346 566 666 140]\n",
      " [517 378 721 805 752 471 458 778 584 813]\n",
      " [312 291 628  36 827 995 791 944 451 178]\n",
      " [726 110 553 802 217 626 392 168 791 467]\n",
      " [483 947 789 977 614 456 250 525 139 510]\n",
      " [375 319  69 244 552 858 700 368 196 126]\n",
      " [256 630  20 674 909 510 735 364 102 340]\n",
      " [631 275 959 768 628 937 303 747 883 116]\n",
      " [636 933 982 599  99 329 496 267 899 656]\n",
      " [589 529 874 795 467 822 757 368 855 252]\n",
      " [983 235 553 612 449  21 434 615 125 291]\n",
      " [170 466 283 233 364 322 436  11 444 684]\n",
      " [426 966  62 816 625 167   2   8 778 870]\n",
      " [376 124 900 313 742 632 396 463 751 536]\n",
      " [896 241 911 512 216 607  60 155 756 560]\n",
      " [122 212 672 477 664 738 884 212 702 573]\n",
      " [736 714  40 616 165 685 807 271 460 333]\n",
      " [727   9  98  15 115 161  13 373  44 493]\n",
      " [961  69 957 571 158 578 956 190  15 724]\n",
      " [980 566 557 955 724 707 280 345 106 457]\n",
      " [509 751 399 101 284 602 952 487 418 523]\n",
      " [377  99 350 643 660 114 689 623 340 571]\n",
      " [ 34 623 920 764 715  14 558 715 957 765]\n",
      " [780 736 330 282 917 226 487 970 962 509]\n",
      " [613 334  83  23 651 547 748 271 333 325]\n",
      " [305 817 891 724 305 246 330 702 711 296]\n",
      " [324 957 593 713 128 450 658 462 900 379]\n",
      " [524 352 203 259 123 942 451   1 675 146]\n",
      " [631 876 738  60 187 416 260 602 135 626]\n",
      " [353 982 385  80 168 883 632 276 615  73]\n",
      " [ 41 168 328  51 649 342 689 922 409 795]\n",
      " [ 49 867 187 651 703 459   6 904 124 597]\n",
      " [226  95 496 574 631 451 186 633 374 980]\n",
      " [970  91 422 697 190 913  54 377 510 561]\n",
      " [750 536 790 475 642  21 309  64 512 679]\n",
      " [307 785 147 227 772 932 670 722 727 230]\n",
      " [637 235 938 753 758 286 214 642 730 863]\n",
      " [105 362 415 972 717 815 819 849 988 772]\n",
      " [774 205 472 555 608 318 722 739 972 534]\n",
      " [788 728 494 218 955 186 329 198 956 217]\n",
      " [874 711 442  54 511 900 552 311 376 517]\n",
      " [500 353 688 499  11 286 404 673 940 577]\n",
      " [600 226 590 793 562 145   3 552 522  18]\n",
      " [367 164 341 352 708 460 543  93   2 218]\n",
      " [618 297 968 503 932 466 426 129 411  38]\n",
      " [959  80 384 591 232 460 978  82  95 360]\n",
      " [827 885 137  57 962 791 509 956 795 555]\n",
      " [829 316 916 134 460  41 964 103 693 181]\n",
      " [634 878 695  13 878 280 950 257  60 708]\n",
      " [137 207 926 583 995 550 337 583  86 580]\n",
      " [224 917 185 612 823 602 207 986 722 165]\n",
      " [977 641 828 996 516 647 705 174 948 792]\n",
      " [967 872 229  69  89 170 871 791 995 279]\n",
      " [782 197 799 546 670 500 816 440 828 872]\n",
      " [394 576 201 805 601 872 234  97 908 760]\n",
      " [703 359 876  52 189 585 984 296 510  16]\n",
      " [983 321 510 819 305 184  74 574 424 632]\n",
      " [309 969 700 647 489 927 551 568 550 217]\n",
      " [325 543 582 363 224 958 785 456 921 959]\n",
      " [798 810 830 553 172 454 245 985 636 639]\n",
      " [643 221 683 865 707 689 292 268 637 162]\n",
      " [805 967 276 101 134 393 743 846 863 715]\n",
      " [606 724 115 272 676 294 739 194 200 772]\n",
      " [913 382 535 727 550 918 548 291 428 581]\n",
      " [880 630 443 413 398 241 517 632   2 774]\n",
      " [396  60 147 158 618 616 876 301 975 650]]\n",
      "X_train's len =  100 10\n",
      "y_train [1 0 1 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1\n",
      " 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0]\n",
      "y_train 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# 1. Prepare sample data\n",
    "# Let's imagine we have some text data, represented as sequences of integers\n",
    "# For simplicity, we'll create some dummy data\n",
    "vocab_size = 1000  # Number of unique words in our vocabulary\n",
    "max_len = 10       # Maximum length of our sequences\n",
    "num_samples = 100  # Number of training samples\n",
    "\n",
    "# Generate random sequences of integers\n",
    "X_train = np.random.randint(1, vocab_size, size=(num_samples, max_len))\n",
    "print('X_train = ', X_train)\n",
    "print('X_train\\'s len = ', len(X_train), len(X_train[0]))\n",
    "y_train = np.random.randint(0, 2, size=(num_samples,)) # Binary classification target\n",
    "print('y_train', y_train)\n",
    "print('y_train', len(y_train))\n",
    "\n",
    "# 2. Build the Bidirectional LSTM model\n",
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "\n",
    "model = Sequential([\n",
    "    # Embedding layer to convert integer indices to dense vectors\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n",
    "    \n",
    "    # Bidirectional LSTM layer\n",
    "    # 'merge_mode' can be 'concat' (default), 'sum', 'mul', 'ave', or None\n",
    "    Bidirectional(LSTM(lstm_units, return_sequences=False)), \n",
    "    \n",
    "    # Output Dense layer for classification\n",
    "    Dense(1, activation='sigmoid') \n",
    "])\n",
    "\n",
    "# 3. Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Print model summary\n",
    "model.summary()\n",
    "\n",
    "# 5. (Optional) Train the model with your prepared data\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4bb25-8bd5-4572-bd95-68eef9189a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# 1. Prepare Data (Example: IMDB movie review sentiment classification)\n",
    "# Load the IMDB dataset\n",
    "max_features = 20000  # vocabulary size\n",
    "maxlen = 200          # sequence length\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Pad sequences to a fixed length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = sequence.pad_sequences(x_val, maxlen=maxlen)\n",
    "\n",
    "# 2. Build the Multi-Layer Bidirectional LSTM Model\n",
    "embedding_dim = 128\n",
    "lstm_units_1 = 64\n",
    "lstm_units_2 = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim)) # Embedding layer to convert word indices to dense vectors\n",
    "\n",
    "# First Bidirectional LSTM layer\n",
    "# return_sequences=True is crucial for stacking LSTM layers\n",
    "model.add(Bidirectional(LSTM(lstm_units_1, return_sequences=True))) \n",
    "\n",
    "# Second Bidirectional LSTM layer\n",
    "# The output of the first BiLSTM is fed as input to the second\n",
    "model.add(Bidirectional(LSTM(lstm_units_2))) \n",
    "\n",
    "# Output layer for classification (e.g., binary classification for sentiment)\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# 3. Compile the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Model Summary (Optional, for understanding the architecture)\n",
    "print(model.summary())\n",
    "\n",
    "# 5. Train the Model (Example with dummy data)\n",
    "# In a real scenario, you would train with your actual data\n",
    "# history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
