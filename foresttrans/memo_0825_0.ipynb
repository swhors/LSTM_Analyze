{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b87a4c-503a-4008-8554-04245d46297d",
   "metadata": {},
   "source": [
    "### _* Memo_0825_0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c551d0-b6c6-48e3-bd74-f79947feffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nums_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}\n",
    "predicted_nums_list = []\n",
    "candidate = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af1d137-cab1-45b5-a8d0-786cdd616261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Configuration\n",
    "\n",
    "version=\"memo_0825_0\"\n",
    "next_round = 1187\n",
    "\n",
    "title = \"Metrics\"\n",
    "row_length = 150\n",
    "new_to_old = True\n",
    "show_mark_down = True\n",
    "markdown_table_limit_length = 30\n",
    "# 1179 3,16,18,24,40,44+21. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2f8015-3542-4119-a0df-107e9525dc4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step #01 [now = 2025-08-22 18:24:35.939381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21400/2490223087.py:21: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "## this code was run.\n",
    "#!pip install keras-tuner\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "print(f'Current Step #01 [now = {datetime.now()}')\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from IPython.display import Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3b5d97d-ed5f-4ec6-a5ef-66eb53be8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidated(version: str):\n",
    "    \"\"\" get_candidated \"\"\"\n",
    "    query = f'select n0, n1, n2, n3, n4, n5 from candidated where version=\\\\\"{version}\\\\\";'\n",
    "    metrics = !echo \"{query}\" | sqlite3 ../db/metrics.db\n",
    "    if len(metrics) == 1:\n",
    "        metrics = metrics[0].split('|')\n",
    "        if len(metrics) == 6:\n",
    "            return {0: int(metrics[0]),\n",
    "                    1: int(metrics[1]),\n",
    "                    2: int(metrics[2]),\n",
    "                    3: int(metrics[3]),\n",
    "                    4: int(metrics[4]),\n",
    "                    5: int(metrics[5])}\n",
    "    return {}\n",
    "\n",
    "\n",
    "def set_candidated_level(version: str, level: int):\n",
    "    \"\"\" set_candidated_level \"\"\"\n",
    "    \"\"\" candidated의 level을 설정합니다. \"\"\" \n",
    "    up_query = f'update candidated set level={level} where version=\\\\\"{version}\\\\\";'\n",
    "    !echo \"{up_query}\" | sqlite3 ../db/metrics.db\n",
    "\n",
    "\n",
    "def get_candidated_level(version: str):\n",
    "    \"\"\" get_candidated_level \"\"\"\n",
    "    \"\"\" level을 가져 옵니다. \"\"\"\n",
    "    sel_query = f'select level from candidated where version=\\\\\"{version}\\\\\";'\n",
    "    levels = !echo \"{sel_query}\" | sqlite3 ../db/metrics.db\n",
    "\n",
    "    if len(levels) > 0:\n",
    "        return int(levels[0])\n",
    "    return 0\n",
    "\n",
    "\n",
    "def update_candidated(candidated: dict, version: str):\n",
    "    \"\"\" update_candidated \"\"\"\n",
    "    sel_query = f'select * from candidated where version=\\\\\"{version}\\\\\";'\n",
    "    metrics = !echo \"{sel_query}\" | sqlite3 ../db/metrics.db\n",
    "    if len(metrics) == 1:\n",
    "        \"\"\" update \"\"\"\n",
    "        update_query = 'update candidated set '\n",
    "        set_kv = []\n",
    "        for key in candidated.keys():\n",
    "            set_kv.append(f'n{key}={candidated[key]}')\n",
    "        update_query += \", \".join(set_kv)\n",
    "        update_query += f' where version=\\\\\"{version}\\\\\";'\n",
    "        !echo \"{update_query}\" | sqlite3 ../db/metrics.db\n",
    "    else:\n",
    "        \"\"\" insert \"\"\"\n",
    "        insert_query = 'insert into candidated ('\n",
    "        new_key = []\n",
    "        new_val = []\n",
    "        for key in candidated.keys():\n",
    "            new_key.append(f'n{key}')\n",
    "            new_val.append(f'{candidated[key]}')\n",
    "        new_key.append('version')\n",
    "        new_val.append(f'\\\\\"{version}\\\\\"')\n",
    "        insert_query += f'{\", \".join(new_key)} ) values ('\n",
    "        insert_query += f'{\", \".join(new_val)} );'\n",
    "        !echo \"{insert_query}\" | sqlite3 ../db/metrics.db\n",
    "\n",
    "\n",
    "def create_candidated():\n",
    "    \"\"\" create_candidated \"\"\"\n",
    "    new_query = 'create table candidated ( ' \\\n",
    "                ' id INTEGER PRIMARY KEY AUTOINCREMENT, ' \\\n",
    "                ' version char[14], ' \\\n",
    "                ' n0 int, ' \\\n",
    "                ' n1 int, ' \\\n",
    "                ' n2 int, ' \\\n",
    "                ' n3 int, ' \\\n",
    "                ' n4 int, ' \\\n",
    "                ' n5 int );'\n",
    "    !echo \"{new_query}\" | sqlite3 ../db/metrics.db\n",
    "\n",
    "\n",
    "def draw_nums(ext_datas, is_pre_data=False, fig_size=(15, 8)):\n",
    "    \"\"\" draw_nums \"\"\"\n",
    "    show_cols = [0, 1, 2, 3, 4, 5]\n",
    "    show_label = False\n",
    "    show_cnt = 100\n",
    "    start_pos = row_length - show_cnt\n",
    "    show_data = []\n",
    "    for i in range(6):\n",
    "        end_pos = -1 if is_pre_data else len(row_list_none_last[i])\n",
    "        show_data.append(row_list_none_last[i][start_pos:end_pos])\n",
    "    print(ext_datas)\n",
    "    draw_scatter(show_data, f'line num : {key}', True, True, show_cols, ext_datas, show_label, helper_line_nums=[10, 20, 30, 40], fig_size=fig_size)\n",
    "\n",
    "\n",
    "# 기준이 되는 수에 대한 DB의 기존 데이터를 출력합니다.\n",
    "def get_likey(like_query, next_round):\n",
    "    \"\"\" get_likey \"\"\"\n",
    "    rows = !echo \"{like_query}\" | sqlite3 ../db/metrics.db\n",
    "    cur_next_round = next_round\n",
    "    if len(rows) > 0:\n",
    "        for row in rows:\n",
    "            cols = row.split(\"|\")\n",
    "            nums = [int(i) for i in cols[2].split(',')]\n",
    "            nums_str = [f\"{int(i): >2}\" for i in nums]\n",
    "            round_diff = 0\n",
    "            cur_round = int(cols[1])        \n",
    "            if next_round > 0:\n",
    "                round_diff = cur_next_round - cur_round\n",
    "            cur_next_round = cur_round\n",
    "            print(f\"{cur_round: >4} | {','.join(nums_str)} | {sum(nums): >3} | {round_diff: >3}\")\n",
    "    else:\n",
    "        print('data is empty.')\n",
    "\n",
    "\n",
    "cur_level = get_candidated_level(version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6132dd4-f20a-49e3-9538-b25458333dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur_level = 0, db_level = 0\n"
     ]
    }
   ],
   "source": [
    "## 레벨을 설정합니다.\n",
    "## 변경시에는 아래의 cur_level을 해제하고 실행하여야 합니다.\n",
    "db_level = get_candidated_level(version=version)\n",
    "print(f'cur_level = {cur_level}, db_level = {db_level}')\n",
    "if cur_level != db_level:\n",
    "    set_candidated_level(version=version, level=cur_level)\n",
    "    db_level = get_candidated_level(version=version)\n",
    "    print(f'cur_level = {cur_level}, db_level = {db_level}')\n",
    "#cur_level = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8117d0af-9ac0-4a26-8f2a-39a5d895dc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row's len = 150\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "###### Updated 2025-08-18 13:05:21.033200\n",
       "\n",
       "### Metrics\n",
       "|round|numbers|bonus|sum|0|10|20|30|40|\n",
       "|--|--|--|--|--|--|--|--|--|\n",
       "|1186|06,17,22,28,29,32|38|134|1|1|3|1|0|\n",
       "|1185|06,17,22,28,29,32|38|134|1|1|3|1|0|\n",
       "|1184|14,16,23,25,31,37|42|146|0|2|2|2|0|\n",
       "|1183|04,15,17,23,27,36|31|122|1|2|2|1|0|\n",
       "|1182|01,13,21,25,28,31|22|119|1|1|3|1|0|\n",
       "|1181|08,10,14,20,33,41|28|126|1|2|1|1|1|\n",
       "|1180|06,12,18,37,40,41|3|154|1|2|0|1|2|\n",
       "|1179|03,16,18,24,40,44|21|145|1|2|1|0|2|\n",
       "|1178|05,06,11,27,43,44|17|136|2|1|1|0|2|\n",
       "|1177|03,07,15,16,19,43|21|103|2|3|0|0|1|\n",
       "|1176|07,09,11,21,30,35|29|113|2|1|1|2|0|\n",
       "|1175|03,04,06,08,32,42|31|95|4|0|0|1|1|\n",
       "|1174|08,11,14,17,36,39|22|125|1|3|0|2|0|\n",
       "|1173|01,05,18,20,30,35|3|109|2|1|1|2|0|\n",
       "|1172|07,09,24,40,42,44|45|166|2|0|1|0|3|\n",
       "|1171|03,06,07,11,12,17|19|56|3|3|0|0|0|\n",
       "|1170|03,13,28,34,38,42|25|158|1|1|1|2|1|\n",
       "|1169|05,12,24,26,39,42|20|148|1|1|2|1|1|\n",
       "|1168|09,21,24,30,33,37|29|154|1|0|2|3|0|\n",
       "|1167|08,23,31,35,39,40|24|176|1|0|1|3|1|\n",
       "|1166|14,23,25,27,29,42|16|160|0|1|4|0|1|\n",
       "|1165|06,07,27,29,38,45|17|152|2|0|2|1|1|\n",
       "|1164|17,18,23,25,38,39|22|160|0|2|2|2|0|\n",
       "|1163|02,13,15,16,33,43|4|122|1|3|0|1|1|\n",
       "|1162|20,21,22,25,28,29|6|145|0|0|6|0|0|\n",
       "|1161|02,12,20,24,34,42|37|134|1|1|2|1|1|\n",
       "|1160|07,13,18,36,39,45|19|158|1|2|0|2|1|\n",
       "|1159|03,09,27,28,38,39|7|144|2|0|2|2|0|\n",
       "|1158|21,25,27,32,37,38|20|180|0|0|3|3|0|\n",
       "|1157|05,07,12,20,25,26|28|95|2|1|3|0|0|\n",
       "###### Updated 2025-08-18 13:05:21.043757"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the variable's value in Markdown\n",
    "contents = f\"###### Updated {datetime.now()}\\n\\n### {title}\\n\"\n",
    "query = 'select round, metric, bonus from results'\n",
    "query += f' order by round {\"desc\" if new_to_old else \"asc\"}'\n",
    "limit_str = f'limit {row_length}'\n",
    "query += f' {limit_str if row_length > 0 else \"\"}'\n",
    "rows = !echo \"{query}\"| sqlite3 ../db/metrics.db\n",
    "table_rows = [\"|round|numbers|bonus|sum|0|10|20|30|40|\",\n",
    "              \"|--|--|--|--|--|--|--|--|--|\"\n",
    "             ]\n",
    "rows_dict = {1:[], 10:[], 20:[], 30:[], 40:[]}\n",
    "nums_t = []\n",
    "sums = []\n",
    "cur_table_limit = 0\n",
    "print(f'row\\'s len = {len(rows)}')\n",
    "for row in rows:\n",
    "    cols = row.split('|')\n",
    "    if len(cols) == 3:\n",
    "        num_00 = 0\n",
    "        num_10 = 0\n",
    "        num_20 = 0\n",
    "        num_30 = 0\n",
    "        num_40 = 0\n",
    "        nums_list = [int(i) for i in cols[1].split(',')]\n",
    "        for num in nums_list:\n",
    "            if num < 10:\n",
    "                num_00 += 1\n",
    "            if num >= 10 and num < 20:\n",
    "                num_10 += 1\n",
    "            if num >= 20 and num < 30:\n",
    "                num_20 += 1\n",
    "            if num >= 30 and num < 40:\n",
    "                num_30 += 1\n",
    "            if num >= 40 :\n",
    "                num_40 += 1\n",
    "        rows_dict[1].append(num_00)\n",
    "        rows_dict[10].append(num_10)\n",
    "        rows_dict[20].append(num_20)\n",
    "        rows_dict[30].append(num_30)\n",
    "        rows_dict[40].append(num_40)\n",
    "        if cur_table_limit < markdown_table_limit_length:\n",
    "            nums=[f\"{i:02}\" for i in nums_list] \n",
    "            table_rows.append(f\"|{cols[0]}|{\",\".join(nums)}|{cols[2]}|{sum(nums_list)}|{num_00}|{num_10}|{num_20}|{num_30}|{num_40}|\")\n",
    "            cur_table_limit += 1\n",
    "        nums_t.append(nums_list)\n",
    "        sums.append(sum(nums_list))\n",
    "sums.reverse()\n",
    "table_rows_str = \"\\n\".join(table_rows)\n",
    "contents+=table_rows_str + \"\\n\" + f\"###### Updated {datetime.now()}\"\n",
    "Markdown(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d0a9e9-63e3-4b24-830a-64273d6112b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data preparation\n",
    "\"\"\"\n",
    "\n",
    "#########\n",
    "# nums_t\n",
    "nums_by_row = [[] for i in range(6)]\n",
    "for nums in nums_t:\n",
    "    for i in range(6):\n",
    "        nums_by_row[i].append(nums[i])\n",
    "for i in range(6):\n",
    "    nums_by_row[i].reverse()\n",
    "\n",
    "##########\n",
    "# row_list\n",
    "row_list = []\n",
    "row_list_none_last = []\n",
    "for nums in nums_by_row:\n",
    "    row_list.append(nums[0:-1])\n",
    "    row_list_none_last.append(nums[0: len(nums)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd0ee53-42d8-445d-8c08-fcb2c5f10975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work : 2025-08-18 13:07:02.000210\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Functions\n",
    "\"\"\"\n",
    "\n",
    "def draw_markdown(rows: list):\n",
    "    from IPython.display import Markdown\n",
    "    # Define a variable\n",
    "    # Display the variable's value in Markdown\n",
    "    table_header = \"|title|content|\"\n",
    "    table_sep = \"|--|--|\"\n",
    "    table_rows = [table_header,\n",
    "                  table_sep,\n",
    "                  ]\n",
    "    for row in rows:\n",
    "        table_rows.append(f\"|{row[0]}|{row[1]}|\")\n",
    "    table_rows_str = \"\\n\".join(table_rows)\n",
    "    Markdown(table_rows_str)\n",
    "    for row in rows:\n",
    "        print(f'{row[0]:12s} = {row[1]}')\n",
    "\n",
    "\n",
    "def draw_graph(X, title):\n",
    "    print(X)\n",
    "    y = [i for i in range(len(X))]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y, X, label='Nums')\n",
    "    plt.xlabel('rounds')\n",
    "    plt.ylabel('selected')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_scatter(Y: list, title, show_line=True, show_dot=True, show_cols=[0], ext_datas=[], show_label=True, helper_line_nums=[], marker_size=3, figsize=(12, 6), save_fig=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "    colors=['b', 'g', 'r', 'c', 'm', 'y']\n",
    "    if show_line == False and show_dot == False:\n",
    "        show_line = True\n",
    "    last = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[]}\n",
    "    \n",
    "    # draw helper line\n",
    "    for helper_line_num in helper_line_nums:\n",
    "        helper_line = [helper_line_num for i in range(len(Y[0]))]\n",
    "        X = [i for i in range(len(Y[0]))]\n",
    "        plt.plot(X, helper_line, color=\"tab:gray\")\n",
    "\n",
    "    for show_col in show_cols:\n",
    "        if show_col < len(Y):\n",
    "            if show_label:\n",
    "                label = f'Nums{show_col}'            \n",
    "            else:\n",
    "                label = \"\"\n",
    "            X = [i for i in range(len(Y[show_col]))]\n",
    "            if show_line:\n",
    "                plt.plot(X, Y[show_col], label=label, color=colors[show_col])\n",
    "                label = \"\"\n",
    "            if show_dot:\n",
    "                plt.plot(X, Y[show_col], marker='o', markersize=marker_size, color = colors[show_col], label=label)\n",
    "        # print(f'show_col = {show_col}')\n",
    "        # print(f'         = {Y[show_col][-1:][0]}')\n",
    "        last[show_col].append(Y[show_col][-1:][0])\n",
    "    if len(ext_datas) > 0:\n",
    "        for ext in ext_datas:\n",
    "            if ext[0] < 6 and ext[0] in last:\n",
    "                show_col = ext[0]\n",
    "                last[show_col].append(ext[1])\n",
    "                loc = np.arange(len(Y[0])-1, len(Y[0]) + len(last[show_col])-1)\n",
    "                if show_line:\n",
    "                    plt.plot(loc, last[show_col], color='k')\n",
    "                if show_dot:\n",
    "                    plt.plot(loc, last[show_col], marker='o', markersize=marker_size, color='k')\n",
    "    plt.xlabel('rounds')\n",
    "    plt.ylabel('selected')\n",
    "    plt.title(title)\n",
    "    if show_label:\n",
    "        plt.legend()\n",
    "    if save_fig:\n",
    "        plt.savefig(f'img/{title}_{datetime.now().strftime('%Y_%m%d_%H%M%S')}')\n",
    "    plt.show()\n",
    "\n",
    "def get_pre_bef(nums, wanted_num):\n",
    "    results = []\n",
    "    for pos in range(len(nums)):\n",
    "        parts = []\n",
    "        if nums[pos] == wanted_num:\n",
    "            if pos > 0 and pos < (len(nums) - 1 ):\n",
    "                parts.append(nums[pos-1])\n",
    "                parts.append(nums[pos])\n",
    "                parts.append(nums[pos+1])\n",
    "            if pos == 0 and pos < (len(nums) - 1 ):\n",
    "                parts.append(-1)\n",
    "                parts.append(nums[pos])\n",
    "                parts.append(nums[pos+1])\n",
    "            if pos >= (len(nums) - 1 ) and pos > 0:\n",
    "                parts.append(nums[pos-1])\n",
    "                parts.append(nums[pos])\n",
    "                parts.append(-1)\n",
    "            results.append(parts)\n",
    "    return results\n",
    "            \n",
    "\n",
    "def draw_average(my_list, length, selected, helper_line_nums=[10,20,30,40], show_diff=False):\n",
    "    print(f'{\"_\"*40}')\n",
    "    averages = []\n",
    "    metrics = []\n",
    "    show_cols = [0]\n",
    "    for i in range(len(my_list) - length):\n",
    "        item_part = my_list[i: i+length]\n",
    "        average = np.mean(item_part)\n",
    "        averages.append(float(average))\n",
    "    metrics.append(averages)\n",
    "    ordered = averages.copy()\n",
    "    ordered.sort()\n",
    "    draw_markdown([('최소값',f'{ordered[0:5]}'),\n",
    "                   ('최대값',f'{ordered[-5:]}'),\n",
    "                   ('마지막',f'{averages[-5:]}')\n",
    "                  ])\n",
    "    if show_diff:\n",
    "        diff = [0] + [averages[i] - averages[i-1] for i in range(1, len(averages), 1)]\n",
    "        metrics.append(diff)\n",
    "        show_cols.append(1)\n",
    "    draw_scatter(metrics, f'average : {selected+1} {length}', True, True, show_cols=show_cols, helper_line_nums=helper_line_nums)\n",
    "\n",
    "\n",
    "def get_frequency(datas):\n",
    "    \"\"\" get_frequency \"\"\"\n",
    "    # datas = my_list.copy()\n",
    "    # datas.sort()\n",
    "    ordered_dict = {}\n",
    "    for key in datas:\n",
    "        if key not in ordered_dict:\n",
    "            ordered_dict[key] = 1\n",
    "        else:\n",
    "            ordered_dict[key] += 1\n",
    "    ordered_dict_sorted = sorted(ordered_dict.items(), key=lambda item: item[1])\n",
    "    return ordered_dict_sorted\n",
    "\n",
    "\n",
    "def get_information(selected, num_data, ext_data, wanted_data_length, helper_line_nums_1, helper_line_nums_2, show_diff=False, lengths=[5,8,10,13,15], start_pos_0=0, start_pos_1=0):\n",
    "    \"\"\" get_information \"\"\"\n",
    "    length = 8\n",
    "    if start_pos_0 > len(num_data):\n",
    "        start_pos_0 = 0\n",
    "    if start_pos_1 > len(num_data):\n",
    "        start_pos_1 = 0\n",
    "    draw_scatter([num_data[start_pos_0:]],\n",
    "                 f'Line Num : {selected+1}',\n",
    "                 True, True,\n",
    "                 [0],\n",
    "                 [(0,ext_data)],\n",
    "                 helper_line_nums=helper_line_nums_1)\n",
    "    # print(f'start_pos_0 = {start_pos_0}')\n",
    "    # print(f'start_pos_1 = {start_pos_1}')\n",
    "    my_list = num_data[start_pos_1:] + [ext_data]\n",
    "    last_num = num_data[-1:][0]\n",
    "    ordered = my_list.copy()\n",
    "    ordered.sort()\n",
    "    ordered = list(set(ordered))\n",
    "    freq_parts = get_frequency(my_list)\n",
    "    freq_all = get_frequency(num_data)\n",
    "    pre_bef = get_pre_bef(num_data, last_num)\n",
    "    draw_markdown([\n",
    "        ('최소 값',f'{ordered[:wanted_data_length]}'),\n",
    "        ('최대 값',f'{ordered[-wanted_data_length:]}'),\n",
    "        ('사용자 선택',f'{ext_data}'),\n",
    "        ('마지막 값',f'{last_num}'),\n",
    "        ('마지막 값들',f'{num_data[-wanted_data_length:]}'),\n",
    "        ('자주 나오는 값(부분)',f'{freq_parts[-wanted_data_length:]}'),\n",
    "        ('자주 나오는 값(전체)',f'{freq_all[-wanted_data_length:]}'),\n",
    "        ('마지막 수의 앞과 뒤',f'{pre_bef}')\n",
    "    ]\n",
    "    )\n",
    "    for length in lengths:\n",
    "        draw_average(my_list, length=length, selected=selected, helper_line_nums=helper_line_nums_2, show_diff=show_diff)\n",
    "\n",
    "\n",
    "class DataScaling():\n",
    "    def __init__(self):\n",
    "        # self._scaler_cls = MinMaxScaler()\n",
    "        self._scaler_cls = StandardScaler()\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        return self._scaler_cls.fit_transform(data)\n",
    "\n",
    "    def inverse_transform(self, datas: list):\n",
    "        inversed_data = []\n",
    "        cnt = 1\n",
    "        for data in datas:\n",
    "            # print(data[0])\n",
    "            cnt += 1\n",
    "            if data[1] == True:\n",
    "                inversed = self._scaler_cls.inverse_transform(data[0].reshape(-1, 1))\n",
    "            else:\n",
    "                inversed = self._scaler_cls.inverse_transform(data[0])\n",
    "            inversed_data.append(inversed)\n",
    "        return inversed_data\n",
    "\n",
    "\n",
    "def analyze_v1(random_state,\n",
    "               row_data,\n",
    "               layer_count=3,\n",
    "               activation='sigmoid',\n",
    "               units=50,\n",
    "               epochs=50,\n",
    "               batch_size=1,\n",
    "               draw_graph=True,\n",
    "               sequence_length=10,\n",
    "               train_ratio=0.85,\n",
    "               verbose=0):\n",
    "    # 1. Prepare the Data\n",
    "    # Create sample time series data\n",
    "    df = pd.DataFrame(zip(row_data), columns=['matched_cnts'])\n",
    "    if verbose > 1:\n",
    "        print('df', df)\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #02 [now = {datetime.now()}]')\n",
    "\n",
    "    data = df['matched_cnts'].values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = DataScaling()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #04 [now = {datetime.now()}]')\n",
    "\n",
    "    # Define sequence length (timesteps)\n",
    "\n",
    "    # Create sequences for training\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:i + sequence_length, 0])\n",
    "        y.append(scaled_data[i + sequence_length, 0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #06 [now = {datetime.now()}]')\n",
    "\n",
    "    # Reshape X for LSTM input (samples, timesteps, features)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #08 [now = {datetime.now()}]')\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(X) * train_ratio)\n",
    "\n",
    "    X_train, X_test, X_last = X[:train_size], X[train_size:], np.array([[y[-1:]]])\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #10 [now = {datetime.now()}]')\n",
    "\n",
    "    tf.random.set_seed(random_state)\n",
    "\n",
    "    # 2. Build the LSTM Model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], 1)))\n",
    "    # model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "    for i in range(layer_count):\n",
    "        model.add(LSTM(units=units, return_sequences=True, activation=activation))\n",
    "    model.add(LSTM(units=units, activation=activation))\n",
    "    model.add(Dense(units=1)) # Output layer for predicting a single value\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #12 [now = {datetime.now()}]')\n",
    "\n",
    "    # 3. Compile and Train the Model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #14 [now = {datetime.now()}]')\n",
    "    # 4. Make Predictions\n",
    "    train_predict = model.predict(X_train, verbose=verbose)\n",
    "    test_predict = model.predict(X_test, verbose=verbose)\n",
    "    last_predict = model.predict(X_last, verbose=verbose)\n",
    "    if verbose > 0:\n",
    "        print(f'Current Step #16 [now = {datetime.now()}]')\n",
    "\n",
    "    # Inverse transform predictions to original scale\n",
    "    scaled_data1 = scaled_data\n",
    "    wanted_datas = [(train_predict, False),\n",
    "                    (test_predict, False),\n",
    "                    (last_predict, True),\n",
    "                    (y_train, True),\n",
    "                    (y_test, True),\n",
    "                    (scaled_data, False)]\n",
    "    inversed_datas = scaler.inverse_transform(wanted_datas)\n",
    "    train_predict = inversed_datas[0]\n",
    "    test_predict = inversed_datas[1]\n",
    "    last_predict = inversed_datas[2]\n",
    "    y_train_original = inversed_datas[3]\n",
    "    y_test_original = inversed_datas[4]\n",
    "    scaled_data = inversed_datas[5]\n",
    "\n",
    "    if verbose > 1:\n",
    "        print(f'Current Step #18 [now = {datetime.now()}]')\n",
    "\n",
    "    # 5. Evaluate the Model (Optional, but recommended)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_original, train_predict))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_original, test_predict))\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f'Current Step #20 [now = {datetime.now()}]')\n",
    "        print(f\"Train RMSE: {train_rmse}\")\n",
    "        print(f\"Test RMSE: {test_rmse}\")\n",
    "        print(f'random_state = {random_state}')\n",
    "        print(f'last_prediction = {last_predict}')\n",
    "        print(f'data_max_val = {scaled_data.max()}')\n",
    "    # You can also visualize the results\n",
    "    if draw_graph:\n",
    "        # import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(scaled_data, label='Original Data')\n",
    "        plt.plot(np.arange(sequence_length,\n",
    "                           sequence_length + len(train_predict)),\n",
    "                 train_predict,\n",
    "                 label='Train Predictions')\n",
    "        plt.plot(np.arange(sequence_length + len(train_predict),\n",
    "                           sequence_length + len(train_predict) + len(test_predict)),\n",
    "                 test_predict,\n",
    "                 label='Test Predictions')\n",
    "        plt.plot(np.arange(sequence_length + len(train_predict) + len(test_predict),\n",
    "                       sequence_length + len(train_predict) + len(test_predict) + len(last_predict)),\n",
    "                 last_predict,\n",
    "                 label='Last Predictions')\n",
    "        plt.xlabel(f'{random_state}\\'s Time Step')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return scaled_data.max(), last_predict, random_state\n",
    "\n",
    "\n",
    "def data_prepare(row_data, train_ratio=0.85, sequence_length=10):\n",
    "    ## data preparation\n",
    "    print(f'Current Step #06 [now = {datetime.now()}]')\n",
    "    df = pd.DataFrame(zip(row_data), columns=['matched_cnts'])\n",
    "    data = df['matched_cnts'].values.reshape(-1, 1)\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    print(f'Current Step #04 [now = {datetime.now()}]')\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled_data) - sequence_length):\n",
    "        X.append(scaled_data[i:i + sequence_length, 0])\n",
    "        y.append(scaled_data[i + sequence_length, 0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    # Reshape X for LSTM input (samples, timesteps, features)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    # Split data into training and testing sets\n",
    "    train_size = int(len(X) * train_ratio)\n",
    "    X_train, X_test, X_last = X[:train_size], X[train_size:], np.array([[y[-1:]]])\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    print(f'Current Step #08 [now = {datetime.now()}]')    \n",
    "    return X_train, X_test, X_last, y_train, y_test, scaler\n",
    "\n",
    "\n",
    "def search_model(X_train, X_test, X_last, y_train, y_test, n_epochs=50, max_trial=50, random_state=355314, validation_split=0.05, title=\"model_cur\", verbose=0):\n",
    "    n_input = X_train.shape[1]\n",
    "    print(f'Current Step #10 [now = {datetime.now()}]')\n",
    "    tf.random.set_seed(random_state)\n",
    "    def build_model(hp):\n",
    "        # print(f'Current Step #20 [now = {datetime.now()}]')    \n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(n_input, 1)))    \n",
    "        model.add(LSTM(units=hp.Int('units',\n",
    "                                    min_value=32,\n",
    "                                    max_value=512,\n",
    "                                    step=32),\n",
    "                       return_sequences=True,\n",
    "                       activation='tanh'))    \n",
    "        model.add(Dense(units=hp.Int('units',\n",
    "                                     min_value=32,\n",
    "                                     max_value=512,\n",
    "                                     step=32),\n",
    "                        activation='tanh'))\n",
    "        model.add(Dense(1))\n",
    "        # print(f'Current Step #22 [now = {datetime.now()}]')    \n",
    "        model.compile(loss='mse', metrics=['mse'], optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])))\n",
    "        # print(f'Current Step #24 [now = {datetime.now()}]')    \n",
    "        return model\n",
    "    \n",
    "    print(f'Current Step #12 [now = {datetime.now()}]')    \n",
    "    bayesian_opt_tuner = BayesianOptimization(\n",
    "        build_model,\n",
    "        objective='mse',\n",
    "        max_trials=max_trial,\n",
    "        # executions_per_trial=1,\n",
    "        directory=os.path.normpath('./models/'),\n",
    "        project_name=title,\n",
    "        overwrite=True)\n",
    "    print(f'Current Step #14 [now = {datetime.now()}]')\n",
    "    if validation_split > 0:\n",
    "        bayesian_opt_tuner.search(X_train,\n",
    "                                  y_train,\n",
    "                                  epochs=n_epochs,\n",
    "                                  # validation_data=(X_test, y_test),\n",
    "                                  validation_split=validation_split,\n",
    "                                  verbose=verbose)\n",
    "    else:\n",
    "        bayesian_opt_tuner.search(X_train,\n",
    "                                  y_train,\n",
    "                                  epochs=n_epochs,\n",
    "                                  verbose=verbose)\n",
    "    print(f'Current Step #16 [now = {datetime.now()}]')    \n",
    "    bayes_opt_model_best_model = bayesian_opt_tuner.get_best_models(num_models=1)\n",
    "    model = bayes_opt_model_best_model[0]\n",
    "    if verbose > -1:\n",
    "        print(model.summary())\n",
    "    print(f'Current Step #18 [now = {datetime.now()}]')    \n",
    "    return model\n",
    "\n",
    "print(f'Current work : {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c3120c-5373-42a4-834f-25273c2d1306",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_nums = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618e348-e925-47f7-8727-d3f952a9c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict sum\n",
    "row_data = sums[:-1]\n",
    "n_epochs = 50\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     title=f\"sum_{datetime.now()}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062260ff-303e-4795-91f5-20c924c0dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict round 1\n",
    "selected = 0\n",
    "## data preparation\n",
    "row_data = row_list_none_last[selected]\n",
    "n_epochs = 50\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     title=f\"predict_{selected+1}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)\n",
    "predicted_nums[selected] = scaled_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fbe29-1825-4fbf-9bdb-0889dbb7bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_nums)\n",
    "\"\"\"\n",
    "datas = {\n",
    "    0: array([[7.29986]], dtype=float32),  # [[7.2682233]]\n",
    "    1: array([[13.28232]], dtype=float32), # [[13.37916]]\n",
    "    2: array([[19.887342]], dtype=float32),# [[20.237844]]\n",
    "    3: array([[25.81733]], dtype=float32), # [[25.917814]]\n",
    "    4: array([[32.65308]], dtype=float32), # [[32.82199]]\n",
    "    5: array([[39.15555]], dtype=float32)  # [[39.29981]\n",
    "}\n",
    "\"\"\"\n",
    "d1 = [7.29986, 13.28232, 19.887342, 25.81733, 32.65308, 39.15555]\n",
    "d2 = [7.2682233, 13.37916, 20.237844, 25.917814, 32.82199, 39.29981]\n",
    "\n",
    "lev = 1/45\n",
    "d3 = [(d1[i]*lev*1000 - d2[i]*1000*lev) for i in range(len(d1))]\n",
    "\n",
    "print(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c5ed8-e937-42ba-acc3-6972947fbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "next = 0\n",
    "result = []\n",
    "last = [8,10,14,20,33,41]\n",
    "for i in d3:\n",
    "    next += i\n",
    "    result.append(next)\n",
    "print(result)\n",
    "result = []\n",
    "for i in range(len(d3)):\n",
    "    result.append(last[i] + d3[i])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d406bb-5fad-4ee3-8b66-b52504f9a51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict round 2\n",
    "selected = 1\n",
    "## data preparation\n",
    "row_data = row_list_none_last[selected]\n",
    "n_epochs = 50\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     title=f\"predict_{selected+1}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)\n",
    "predicted_nums[selected] = scaled_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bdf144-5c94-42cf-b534-5eeee7a720ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict round 3\n",
    "selected = 2\n",
    "## data preparation\n",
    "row_data = row_list_none_last[selected]\n",
    "n_epochs = 50\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     title=f\"predict_{selected+1}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)\n",
    "predicted_nums[selected] = scaled_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c1bd0-29f7-4ed7-9c7d-a0136562ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict round 4\n",
    "selected = 3\n",
    "## data preparation\n",
    "row_data = row_list_none_last[selected]\n",
    "n_epochs = 50\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     title=f\"predict_{selected+1}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)\n",
    "predicted_nums[selected] = scaled_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "986d52c5-e186-4e3b-8135-24615320bf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step #06 [now = 2025-07-24 16:52:29.396084]\n",
      "Current Step #04 [now = 2025-07-24 16:52:29.409023]\n",
      "Current Step #08 [now = 2025-07-24 16:52:29.409740]\n",
      "Current Step #10 [now = 2025-07-24 16:52:29.410274]\n",
      "Current Step #12 [now = 2025-07-24 16:52:29.505738]\n",
      "Current Step #14 [now = 2025-07-24 16:52:29.592956]\n",
      "Current Step #16 [now = 2025-07-24 16:55:03.608410]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">334,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m288\u001b[0m)        │       \u001b[38;5;34m334,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m288\u001b[0m)        │        \u001b[38;5;34m83,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">417,601</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m417,601\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">417,601</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m417,601\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Current Step #18 [now = 2025-07-24 16:55:05.300619]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0xfffe3a15c2c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "predicted =  [[[-0.00983651]]] [[32.82199]]\n"
     ]
    }
   ],
   "source": [
    "### predict round 5\n",
    "selected = 4\n",
    "## data preparation\n",
    "row_data = row_list_none_last[selected]\n",
    "n_epochs = 25\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "validation_split = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     validation_split = validation_split,\n",
    "                     title=f\"predict_{selected+1}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)\n",
    "predicted_nums[selected] = scaled_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03f59a94-a359-4ccd-aba3-3a028ce408a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step #06 [now = 2025-07-24 16:56:17.668402]\n",
      "Current Step #04 [now = 2025-07-24 16:56:17.681676]\n",
      "Current Step #08 [now = 2025-07-24 16:56:17.683448]\n",
      "Current Step #10 [now = 2025-07-24 16:56:17.684023]\n",
      "Current Step #12 [now = 2025-07-24 16:56:17.808002]\n",
      "Current Step #14 [now = 2025-07-24 16:56:17.912489]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Step #16 [now = 2025-07-24 17:00:01.464116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m4,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,441</span> (21.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,441\u001b[0m (21.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,441</span> (21.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,441\u001b[0m (21.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Current Step #18 [now = 2025-07-24 17:00:05.180278]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "predicted =  [[[0.00946619]]] [[39.29981]]\n"
     ]
    }
   ],
   "source": [
    "### predict round 6\n",
    "selected = 5\n",
    "## data preparation\n",
    "row_data = row_list_none_last[selected]\n",
    "n_epochs = 50\n",
    "max_trial = 25\n",
    "verbose = 0\n",
    "validation_split = 0\n",
    "X_train, X_test, X_last, y_train, y_test, scaler = data_prepare(row_data)\n",
    "model = search_model(X_train=X_train,\n",
    "                     X_test=X_test,\n",
    "                     X_last=X_last,\n",
    "                     y_train=y_train,\n",
    "                     y_test=y_test,\n",
    "                     n_epochs=n_epochs,\n",
    "                     max_trial=max_trial,\n",
    "                     validation_split = validation_split,\n",
    "                     title=f\"predict_{selected+1}\",\n",
    "                     verbose=verbose)\n",
    "predicted = model.predict(X_last)\n",
    "scaled_predicted = scaler.inverse_transform(predicted.reshape(-1, 1))\n",
    "print('predicted = ', predicted, scaled_predicted)\n",
    "predicted_nums[selected] = scaled_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4521713-f9bf-421a-9766-36417c84b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "int [0, 0, 0, 0, 0, 0]\n",
      "sum 0\n"
     ]
    }
   ],
   "source": [
    "predicted_nums_list_0 = [float(i) for i in predicted_nums.values()]\n",
    "predicted_nums_list_1 = [round(i) for i in predicted_nums_list_0]\n",
    "\n",
    "print('float', predicted_nums_list_0)\n",
    "print('int', predicted_nums_list_1)\n",
    "print('sum', sum(predicted_nums_list_1))\n",
    "for i in range(len(predicted_nums_list_1)):\n",
    "    predicted_nums_dict[i] = predicted_nums_list_1[i]\n",
    "predicted_nums_list = predicted_nums_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0e5a5-2837-4b77-8d32-b0e9e942ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.float64(30.000000000000004), array([[6.1207676]], dtype=float32), 314558)\n",
    "(np.float64(33.0), array([[4.0026402]], dtype=float32), 314558)\n",
    "(np.float64(35.0), array([[15.271533]], dtype=float32), 314558)\n",
    "(np.float64(40.0), array([[29.240566]], dtype=float32), 314558)\n",
    "(np.float64(44.0), array([[37.42968]], dtype=float32), 314558)\n",
    "(np.float64(45.0), array([[32.72621]], dtype=float32), 314558)\n",
    "\n",
    "(np.float64(30.0), array([[7.3217187]], dtype=float32), 314558)\n",
    "(np.float64(33.0), array([[13.810979]], dtype=float32), 314558)\n",
    "(np.float64(35.0), array([[19.010557]], dtype=float32), 314558)\n",
    "(np.float64(40.0), array([[25.239151]], dtype=float32), 314558)\n",
    "(np.float64(44.0), array([[34.730366]], dtype=float32), 314558)\n",
    "(np.float64(45.0), array([[38.54149]], dtype=float32), 314558)\n",
    "\n",
    "(np.float64(30.0), array([[8.11678]], dtype=float32), 30014558)\n",
    "(np.float64(33.0), array([[13.650756]], dtype=float32), 30014558)\n",
    "(np.float64(35.0), array([[19.386393]], dtype=float32), 30014558)\n",
    "(np.float64(40.0), array([[25.771692]], dtype=float32), 30014558)\n",
    "(np.float64(44.0), array([[32.6605]], dtype=float32), 30014558)\n",
    "(np.float64(45.0), array([[39.21304]], dtype=float32), 30014558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47adccd1-8fff-437e-8f1f-ae0659502fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_by_row = [[] for i in range(6)]\n",
    "for nums in nums_t:\n",
    "    for i in range(6):\n",
    "        nums_by_row[i].append(nums[i])\n",
    "for i in range(6):\n",
    "    nums_by_row[i].reverse()\n",
    "\n",
    "\n",
    "##########\n",
    "# row_list\n",
    "row_list = []\n",
    "row_list_none_last = []\n",
    "for nums in nums_by_row:\n",
    "    row_list.append(nums[0:-1])\n",
    "    row_list_none_last.append(nums[0: len(nums)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e334e-5b3a-4f69-a75d-98bf682bfc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext_datas = []\n",
    "# for key in candidate:\n",
    "#     ext_datas.append((key, candidate[key]))\n",
    "ext_datas = [(i, predicted_nums_list[i]) for i in range(len(predicted_nums_list))]\n",
    "show_cols = [0, 1, 2, 3, 4, 5]\n",
    "helper_line_nums = []\n",
    "\n",
    "show_label = False\n",
    "start_pos = 50\n",
    "show_datas = []\n",
    "for row in row_list:\n",
    "    show_datas.append(row[start_pos:])\n",
    "\n",
    "draw_scatter(show_datas,\n",
    "             'all line num',\n",
    "             True, True,\n",
    "             show_cols,\n",
    "             ext_datas,\n",
    "             show_label,\n",
    "             helper_line_nums=helper_line_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93bc1b-beb9-4aa5-b415-5a53910eec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_scatter([sums[:-1]] + [sum(predicted_nums_list)], f'Sums')\n",
    "print(f'last : {sums[-10:-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581b49b6-e625-4eee-b109-6749373061e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.float64(30.000000000000004), array([[6.1207676]], dtype=float32), 314558)\n",
    "(np.float64(33.0), array([[4.0026402]], dtype=float32), 314558)\n",
    "(np.float64(35.0), array([[15.271533]], dtype=float32), 314558)\n",
    "(np.float64(40.0), array([[29.240566]], dtype=float32), 314558)\n",
    "(np.float64(44.0), array([[37.42968]], dtype=float32), 314558)\n",
    "(np.float64(45.0), array([[32.72621]], dtype=float32), 314558)\n",
    "\n",
    "(np.float64(30.0), array([[7.3217187]], dtype=float32), 314558)\n",
    "(np.float64(33.0), array([[13.810979]], dtype=float32), 314558)\n",
    "(np.float64(35.0), array([[19.010557]], dtype=float32), 314558)\n",
    "(np.float64(40.0), array([[25.239151]], dtype=float32), 314558)\n",
    "(np.float64(44.0), array([[34.730366]], dtype=float32), 314558)\n",
    "(np.float64(45.0), array([[38.54149]], dtype=float32), 314558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5caae-f772-4090-808b-7eca5fdf8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 1\n",
    "############################\n",
    "selected = Round - 1\n",
    "ext_data = predicted_nums_list[selected]\n",
    "wanted_data_length = 30\n",
    "helper_line_nums_1 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30, 35]\n",
    "helper_line_nums_2 = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 9, 11]\n",
    "lengths = [2, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "start_pos_0 = 150\n",
    "start_pos_1 = 300\n",
    "num_data=row_list_none_last[selected]\n",
    "get_information(selected=selected,\n",
    "                num_data=num_data,\n",
    "                ext_data=ext_data,\n",
    "                wanted_data_length=wanted_data_length,\n",
    "                helper_line_nums_1=helper_line_nums_1,\n",
    "                helper_line_nums_2=helper_line_nums_2,\n",
    "                show_diff=True,\n",
    "                lengths=lengths,\n",
    "                start_pos_0=start_pos_0,\n",
    "                start_pos_1=start_pos_1\n",
    "               )\n",
    "candidate[selected] = ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a6972-8e12-4d66-803b-8e73482448fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 2\n",
    "############################\n",
    "selected = Round - 1\n",
    "ext_data = predicted_nums_list[selected]\n",
    "wanted_data_length = 30\n",
    "helper_line_nums_1 = [0, 1, 2, 3, 4, 5, 7, 8, 10, 15, 20, 25, 30, 35]\n",
    "helper_line_nums_2 = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 9, 11]\n",
    "lengths = [2, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "start_pos_0 = 150\n",
    "start_pos_1 = 300\n",
    "num_data=row_list_none_last[selected]\n",
    "get_information(selected=selected,\n",
    "                num_data=num_data,\n",
    "                ext_data=ext_data,\n",
    "                wanted_data_length=wanted_data_length,\n",
    "                helper_line_nums_1=helper_line_nums_1,\n",
    "                helper_line_nums_2=helper_line_nums_2,\n",
    "                show_diff=True,\n",
    "                lengths=lengths,\n",
    "                start_pos_0=start_pos_0,\n",
    "                start_pos_1=start_pos_1\n",
    "               )\n",
    "candidate[selected] = ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2e54c-48ab-4f66-9506-2fb910ba8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 3\n",
    "############################\n",
    "selected = Round - 1\n",
    "ext_data = predicted_nums_list[selected]\n",
    "wanted_data_length = 30\n",
    "helper_line_nums_1 = [0, 1, 2, 3, 4, 5, 7, 8, 10, 15, 20, 25, 30, 35]\n",
    "helper_line_nums_2 = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 9, 11]\n",
    "lengths = [2, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "start_pos_0 = 150\n",
    "start_pos_1 = 300\n",
    "num_data=row_list_none_last[selected]\n",
    "get_information(selected=selected,\n",
    "                num_data=num_data,\n",
    "                ext_data=ext_data,\n",
    "                wanted_data_length=wanted_data_length,\n",
    "                helper_line_nums_1=helper_line_nums_1,\n",
    "                helper_line_nums_2=helper_line_nums_2,\n",
    "                show_diff=True,\n",
    "                lengths=lengths,\n",
    "                start_pos_0=start_pos_0,\n",
    "                start_pos_1=start_pos_1\n",
    "               )\n",
    "candidate[selected] = ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a74c7-4929-41b1-af60-8213c87c92e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 4\n",
    "############################\n",
    "selected = Round - 1\n",
    "ext_data = predicted_nums_list[selected]\n",
    "wanted_data_length = 30\n",
    "helper_line_nums_1 = [0, 1, 2, 3, 4, 5, 7, 8, 10, 15, 20, 25, 30, 35]\n",
    "helper_line_nums_2 = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 9, 11]\n",
    "lengths = [2, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "start_pos_0 = 150\n",
    "start_pos_1 = 300\n",
    "num_data=row_list_none_last[selected]\n",
    "get_information(selected=selected,\n",
    "                num_data=num_data,\n",
    "                ext_data=ext_data,\n",
    "                wanted_data_length=wanted_data_length,\n",
    "                helper_line_nums_1=helper_line_nums_1,\n",
    "                helper_line_nums_2=helper_line_nums_2,\n",
    "                show_diff=True,\n",
    "                lengths=lengths,\n",
    "                start_pos_0=start_pos_0,\n",
    "                start_pos_1=start_pos_1\n",
    "               )\n",
    "candidate[selected] = ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5a48e-7dac-40f0-a281-6ab003a86a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 5\n",
    "############################\n",
    "selected = Round - 1\n",
    "ext_data = predicted_nums_list[selected]\n",
    "wanted_data_length = 30\n",
    "helper_line_nums_1 = [0, 1, 2, 3, 4, 5, 7, 8, 10, 15, 20, 25, 30, 35]\n",
    "helper_line_nums_2 = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 9, 11]\n",
    "lengths = [2, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "start_pos_0 = 150\n",
    "start_pos_1 = 300\n",
    "num_data=row_list_none_last[selected]\n",
    "\n",
    "get_information(selected=selected,\n",
    "                num_data=num_data,\n",
    "                ext_data=ext_data,\n",
    "                wanted_data_length=wanted_data_length,\n",
    "                helper_line_nums_1=helper_line_nums_1,\n",
    "                helper_line_nums_2=helper_line_nums_2,\n",
    "                show_diff=True,\n",
    "                lengths=lengths,\n",
    "                start_pos_0=start_pos_0,\n",
    "                start_pos_1=start_pos_1\n",
    "               )\n",
    "candidate[selected] = ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31026c7f-5ec3-4ba1-b2ab-5dd5b83b0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = 6\n",
    "############################\n",
    "selected = Round - 1\n",
    "ext_data = predicted_nums_list[selected]\n",
    "wanted_data_length = 30\n",
    "helper_line_nums_1 = [0, 1, 2, 3, 4, 5, 7, 8, 10, 15, 20, 25, 30, 35]\n",
    "helper_line_nums_2 = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 7, 9, 11]\n",
    "lengths = [2, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "start_pos_0 = 150\n",
    "start_pos_1 = 300\n",
    "num_data=row_list_none_last[selected]\n",
    "\n",
    "get_information(selected=selected,\n",
    "                num_data=num_data,\n",
    "                ext_data=ext_data,\n",
    "                wanted_data_length=wanted_data_length,\n",
    "                helper_line_nums_1=helper_line_nums_1,\n",
    "                helper_line_nums_2=helper_line_nums_2,\n",
    "                show_diff=True,\n",
    "                lengths=lengths,\n",
    "                start_pos_0=start_pos_0,\n",
    "                start_pos_1=start_pos_1\n",
    "               )\n",
    "candidate[selected] = ext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48bc1f82-becc-4af3-bf24-a05b197f2566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 13, 20, 26, 33, 39]\n",
      "{0: array([[7.29986]], dtype=float32), 1: array([[13.28232]], dtype=float32), 2: array([[19.887342]], dtype=float32), 3: array([[25.81733]], dtype=float32), 4: array([[32.65308]], dtype=float32), 5: array([[39.15555]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(predicted_nums_list)\n",
    "print(predicted_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c656d96d-ebbc-4642-93a1-f072c6422755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memo_0811_ =\n",
      "         ( [ 2,  9, 11, 28, 29, 34)], 113, 1, '*1' )\n",
      "         ( [ 3,  6, 12, 16, 32, 36)], 105, 2, '*2' )\n",
      "         ( [ 9, 14, 27, 30, 37, 43)], 160, 3, '*2' )\n",
      "         ( [ 3,  6, 13, 24, 32, 37)], 115, 4, '*2' )\n",
      "         ( [12, 14, 17, 25, 26, 41)], 135, 5, '*1' )\n",
      "         ( [ 1,  3,  7, 14, 25, 36)],  86, 6, '*1' )\n",
      "         ( [10, 16, 18, 28, 30, 33)], 135, 7, '*1' )\n",
      "         ( [ 1,  6, 10, 16, 36, 42)], 111, 8, '*1' )\n",
      "         ( [ 9, 15, 28, 29, 38, 45)], 164, 9, '*2' )\n",
      "----------------------------------------------------\n",
      "memo_0818_ =\n",
      "         ( [10, 16, 18, 28, 30, 33)], 135, 1, '*0' )\n",
      "         ( [ 2,  4, 11, 17, 25, 40)],  99, 2, '*1' )\n",
      "         ( [10, 11, 14, 16, 27, 37)], 115, 3, '*1' )\n",
      "         ( [ 2,  8, 12, 30, 31, 40)], 123, 4, '*1' )\n",
      "         ( [ 2, 14, 16, 18, 21, 30)], 101, 5, '*0' )\n",
      "         ( [ 7, 13, 21, 26, 38, 42)], 147, 6, '*1' )\n",
      "         ( [ 5, 15, 22, 27, 33, 39)], 141, 7, '*1' )\n",
      "         ( [ 3,  7, 14, 18, 27, 33)], 102, 8, '*0' )\n",
      "----------------------------------------------------\n",
      "1186 |  2, 8,13,16,23,28 | 90\n"
     ]
    }
   ],
   "source": [
    "version_prefixes=[\"memo_0811_\", \"memo_0818_\"]\n",
    "predict_dict = {}\n",
    "for version_prefix in version_prefixes:\n",
    "    query = f'select version, n0, n1, n2, n3, n4, n5, level from candidated where version like \\\\\"{version_prefix}%\\\\\" order by version asc'\n",
    "    predict_lines = []    \n",
    "    rows = !echo \"{query}\" | sqlite3 ../db/metrics.db\n",
    "    for row in rows:\n",
    "        cols = row.split('|')\n",
    "        level = cols[len(cols)-1]\n",
    "        version_id = int(cols[0].split(version_prefix)[1])\n",
    "        nums = [int(cols[i]) for i in range(1, len(cols) - 1)]\n",
    "        sum_val = sum(nums)\n",
    "        nums_str = []\n",
    "        for num in nums:\n",
    "            nums_str.append(f'{num: >2}')\n",
    "        predict_lines.append(f'( [{\", \".join(nums_str)})], {sum_val: >3}, {version_id}, \\'*{level}\\' )')\n",
    "    predict_dict[version_prefix] = predict_lines\n",
    "\n",
    "for k, vs in predict_dict.items():\n",
    "    print(k, '=')\n",
    "    for v in vs:\n",
    "        print(' '*8, v)\n",
    "    print('-'*52)\n",
    "sel_query = f'select * from results where round=\\\\\"{next_round}\\\\\";'\n",
    "rows = !echo \"{sel_query}\" | sqlite3 ../db/metrics.db\n",
    "cols = rows[0].split('|')\n",
    "nums = [int(i) for i in cols[2].split(',')]\n",
    "print(f'{next_round-1} | {nums[0]: >2},{nums[1]: >2},{nums[2]: >2},{nums[3]: >2},{nums[4]: >2},{nums[5]: >2} | {sum(nums)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32e90a80-312f-4f94-b5ed-475ec86d2b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update results set metric=\\\"6,17,22,28,29,32\\\", bonus=38 where round=1185;\n",
      "insert into results(round, metric, bonus) values(1185, \\\"6,17,22,28,29,32\\\", 38);\n"
     ]
    }
   ],
   "source": [
    "\n",
    "2·8·13·16·23·28, 35\n",
    "\n",
    "update_query = 'update results set metric=\\\\\"6,17,22,28,29,32\\\\\", bonus=38 where round=1185;'\n",
    "insert_query = 'insert into results(round, metric, bonus) values(1185, \\\\\"6,17,22,28,29,32\\\\\", 38);'\n",
    "queries = [update_query, insert_query]\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    !echo \"{query}\" | sqlite3 ../db/metrics.db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac89f1f-083e-4369-9703-f747bd7020e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 39)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:39\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m]\u001b[39m\n     ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# '17·6·32·28·29·22'…보너스 '38'\n",
    "# update results set metric='6,17,22,28,29,32', bonus where round=1185;\n",
    "# insert into results(round, metric, bonus) values(1185, '6,17,22,28,29,32', 1185);\n",
    "# 4\n",
    "1183 | 04,15,17,23,27,36 | 122\n",
    "1184 | 14,16,23,25,31,37 | 146\n",
    "candidate = [(129, [2, 10, 12, 30, 33, 42]),\n",
    "             (141, [13, 14, 16, 25, 35, 38]),\n",
    "             (147, [13, 14, 15, 32, 35, 38]),\n",
    "             (126, [1, 3, 21, 28, 33, 40]),\n",
    "             (138, [7, 13, 20, 26, 33, 39])]\n",
    "\n",
    "predicteds = [\n",
    "    [\n",
    "        [2, 10, 12, 30, 33, 42],\n",
    "        [1, 14, 28, 35, 38, 45],\n",
    "        [6, 13, 15, 28, 30, 42]\n",
    "    ],\n",
    "    [\n",
    "        [1, 14, 28, 35, 38, 45],\n",
    "        [2,  9, 20, 30, 35, 45],\n",
    "        [8,  9, 15, 28, 35, 37]\n",
    "    ],\n",
    "    [\n",
    "        ([13, 16, 21, 24, 41, 45],3, '*0'),\n",
    "        ([ 9, 11, 15, 21, 32, 39],4, '*1'),\n",
    "        ([ 4,  6, 15, 26, 37, 45],5, '*0'),\n",
    "        ([ 2,  6, 12, 19, 38, 45],6, '*1'),\n",
    "        ([11, 13, 23, 24, 38, 45],7, '*0'),\n",
    "        ([ 4,  8, 13, 23, 35, 41],8, '*0'),\n",
    "    ],\n",
    "    [\n",
    "        ([ 1,  6, 12, 26, 37, 45)],1, '*0'),\n",
    "        ([ 3,  6, 14, 23, 32, 38)],2, '*0'),\n",
    "        ([ 6,  8, 11, 35, 36, 43)],3, '*0'),\n",
    "        ([ 4,  6, 24, 35, 38, 44)],4, '*0'),\n",
    "        ([ 6,  9, 16, 18, 32, 39)],5, '*0'),\n",
    "        ([ 4,  7, 10, 18, 30, 31)],6, '*0')\n",
    "    ]\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "4,15,17,23,27,36+31\n",
    "\"\"\"\n",
    "\n",
    "current = len(predicteds)-1\n",
    "\n",
    "for predicted in predicteds[current]:\n",
    "    predicted_strs = [f\"{i:0>2}\" for i in predicted]\n",
    "    print(\",\".join(predicted_strs), sum(predicted))\n",
    "\n",
    "\n",
    "memo_0728_ =\n",
    "         ( [13, 16, 21, 24, 41, 45)], 3, '*0' )\n",
    "         ( [ 9, 11, 15, 21, 32, 39)], 4, '*0' )\n",
    "         ( [ 4,  6, 15, 26, 37, 45)], 5, '*0' )\n",
    "         ( [ 2,  6, 12, 19, 38, 45)], 6, '*0' )\n",
    "         ( [11, 13, 23, 24, 38, 45)], 7, '*0' )\n",
    "         ( [ 4,  8, 13, 23, 35, 41)], 8, '*0' )\n",
    "-----------------------------------------------\n",
    "memo_0804_ =\n",
    "         ( [ 1,  6, 12, 26, 37, 45)], 1, '*1' )\n",
    "         ( [ 3,  6, 13, 24, 32, 37)], 2, '*1' )\n",
    "         ( [15, 17, 24, 32, 39, 45)], 3, '*2' )\n",
    "         ( [10, 11, 24, 33, 38, 43)], 4, '*1' )\n",
    "         ( [ 6,  9, 16, 18, 32, 39)], 5, '*2' )\n",
    "         ( [ 4,  7, 10, 18, 30, 31)], 6, '*2' )\n",
    "         ( [ 1,  6, 12, 19, 26, 28)], 7, '*1' )\n",
    "         ( [ 3,  6, 12, 16, 32, 36)], 8, '*1' )\n",
    "         ( [ 5,  7, 24, 27, 31, 33)], 9, '*2' )\n",
    "-----------------------------------------------\n",
    "1184 = \n",
    "         ( [14, 16, 23, 25, 31, 37], 42, '**' )\n",
    "-----------------------------------------------\n",
    "2 28 8 23 16 13  35\n",
    "\n",
    "2·8·13·16·23·28, 35\n",
    "\n",
    "'17·6·32·28·29·22'…보너스 '38'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad2f21-d6ee-4912-8f84-b061995e5c4b",
   "metadata": {},
   "source": [
    "```\n",
    "round \tnumbers \t     bonus \tsum \t0 \t10 \t20 \t30 \t40\n",
    "1183 \t04,15,17,23,27,36 \t31 \t122 \t1 \t2 \t2 \t1 \t0\n",
    "1182\t01,13,21,25,28,31\t22\t119 \t1\t1\t3\t1\t0\n",
    "1181\t08,10,14,20,33,41\t28\t126 \t1\t2\t1\t1\t1\n",
    "1180\t06,12,18,37,40,41\t3\t154 \t1\t2\t0\t1\t2\n",
    "1179\t03,16,18,24,40,44\t21\t145 \t1\t2\t1\t0\t2\n",
    "1178\t05,06,11,27,43,44\t17\t136 \t2\t1\t1\t0\t2\n",
    "1177\t03,07,15,16,19,43\t21\t103 \t2\t3\t0\t0\t1\n",
    "1177 \t03,07,15,16,19,43 \t21 \t103 \t2 \t3 \t0 \t0 \t1\n",
    "1176 \t07,09,11,21,30,35 \t29 \t113 \t2 \t1 \t1 \t2 \t0\n",
    "1175 \t03,04,06,08,32,42 \t31 \t95 \t    4 \t0 \t0 \t1 \t1\n",
    "1174 \t08,11,14,17,36,39 \t22 \t125 \t1 \t3 \t0 \t2 \t0\n",
    "1173 \t01,05,18,20,30,35 \t3 \t109 \t2 \t1 \t1 \t2 \t0\n",
    "1172 \t07,09,24,40,42,44 \t45 \t166 \t2 \t0 \t1 \t0 \t3\n",
    "1171 \t03,06,07,11,12,17 \t19 \t56 \t    3 \t3 \t0 \t0 \t0\n",
    "1170 \t03,13,28,34,38,42 \t25 \t158 \t1 \t1 \t1 \t2 \t1\n",
    "1169 \t05,12,24,26,39,42 \t20 \t148 \t1 \t1 \t2 \t1 \t1\n",
    "1168 \t09,21,24,30,33,37 \t29 \t154 \t1 \t0 \t2 \t3 \t0\n",
    "1167 \t08,23,31,35,39,40 \t24 \t176 \t1 \t0 \t1 \t3 \t1\n",
    "1166 \t14,23,25,27,29,42 \t16 \t160 \t0 \t1 \t4 \t0 \t1\n",
    "1165 \t06,07,27,29,38,45 \t17 \t152 \t2 \t0 \t2 \t1 \t1\n",
    "1164 \t17,18,23,25,38,39 \t22 \t160 \t0 \t2 \t2 \t2 \t0\n",
    "1163 \t02,13,15,16,33,43 \t4 \t122 \t1 \t3 \t0 \t1 \t1\n",
    "1162 \t20,21,22,25,28,29 \t6 \t145 \t0 \t0 \t6 \t0 \t0\n",
    "1161 \t02,12,20,24,34,42 \t37 \t134 \t1 \t1 \t2 \t1 \t1\n",
    "1160 \t07,13,18,36,39,45 \t19 \t158 \t1 \t2 \t0 \t2 \t1\n",
    "1159 \t03,09,27,28,38,39 \t7 \t144 \t2 \t0 \t2 \t2 \t0\n",
    "1158 \t21,25,27,32,37,38 \t20 \t180 \t0 \t0 \t3 \t3 \t0\n",
    "1157 \t05,07,12,20,25,26 \t28 \t95 \t    2 \t1 \t3 \t0 \t0\n",
    "1156 \t30,31,34,39,41,45 \t7 \t220 \t0 \t0 \t0 \t4 \t2\n",
    "1155 \t10,16,19,27,37,38 \t13 \t147 \t0 \t3 \t1 \t2 \t0\n",
    "1154 \t04,08,22,26,32,38 \t27 \t130 \t2 \t0 \t2 \t2 \t0\n",
    "1153 \t01,09,10,13,35,44 \t5 \t112 \t2 \t2 \t0 \t1 \t1\n",
    "1152 \t30,31,32,35,36,37 \t5 \t201 \t0 \t0 \t0 \t6 \t0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecb8e5-14c6-4184-8644-d300ffafece6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
