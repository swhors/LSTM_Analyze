{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with LSTM model (vT_01_16)\n",
    "<p style='text-align: right;'>with selectd6.csv</p>\n",
    "\n",
    "* history\n",
    "  * 2025/05/23 PM06:02 : 3번째 모델의 3번째 데이터를 사용\n",
    "  * 2025/05/27\n",
    "  * 2025/05/30 : v4.5.1 작성 시작\n",
    "  * 2025/06/04 : v4.5.2 last update\n",
    "  * 2025/06/04 : v4.6.1 작성 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install numpy pandas keras scikit-learn matplotlib scikeras\n",
    "from datetime import datetime\n",
    "print(f'restart kernel... {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python312.zip', '/opt/conda/lib/python3.12', '/opt/conda/lib/python3.12/lib-dynload', '', '/opt/conda/lib/python3.12/site-packages', '/home/jovyan/work/LSTM_Analyze']\n"
     ]
    }
   ],
   "source": [
    "def restart_kernel():\n",
    "    # Restart the kernet after libraries are loaded.\n",
    "    import IPython\n",
    "    from datetime import datetime\n",
    "    print(f'restart kernel... {datetime.now()}')\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)\n",
    "\n",
    "# restart_kernel()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(cwd)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported library. (2025-07-03 14:26:52.536834)\n"
     ]
    }
   ],
   "source": [
    "# load dependacies\n",
    "import os\n",
    "import time\n",
    "import resource\n",
    "from datetime import datetime\n",
    "from lib.globalvar import *\n",
    "from lib.data_loader import DataLoader\n",
    "from lib.small_predict import predict_small, print_predict_small\n",
    "from lib.activation import ActivationOutput, RecurrentActivation\n",
    "from lib.small_predict import build_and_predict, gen_multi_model, save_model, generate_metric\n",
    "from lib.common_env_sets import lstm_units, dense_units, steps, metrics, dropout\n",
    "from lib.common_env_sets import learning_rate, last_lstm_return_sequences\n",
    "from lib.common_env_sets import loss, output_dense_activation, epochs, rand_seed\n",
    "\n",
    "\n",
    "print(f\"imported library. ({datetime.now()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished to set environemnt. (2025-07-03 14:27:01.550454)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## 모델링 환경 설정\n",
    "##\n",
    "window=1 # default = 1 , help = \"time stamps\"\n",
    "data_dir='./csv/selectd6.csv'\n",
    "\n",
    "mode='predict' # help = \"back-test or predict\")\n",
    "\n",
    "mode2='sampling' # help = \"greed or sampling\")\n",
    "verb='verbose' # help = \"verbose or not_verb\")\n",
    "    \n",
    "training_length=0.95 # default = 0.9)\n",
    "from_pos = 0\n",
    "last = [[3, 4, 6, 8, 32, 42],\n",
    "        [8, 11, 14, 17, 36, 39],\n",
    "        [1, 5, 18, 20, 30, 35],\n",
    "        [7, 9, 24, 40, 42, 44],\n",
    "        [3, 6, 7, 11, 12, 17],\n",
    "        [3, 13, 28, 34, 38, 42],\n",
    "        [5, 12, 24, 29, 32, 42]]\n",
    "print(f\"finished to set environemnt. ({datetime.now()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to load data. 2025-06-06 02:03:55.559866\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = {\n",
    "    1: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=0,\n",
    "                  verbose=False\n",
    "                  ),\n",
    "    2: DataLoader(data_dir=data_dir,\n",
    "                  training_length=training_length,\n",
    "                  window_prev=window,\n",
    "                  mode=mode,\n",
    "                  from_pos=300,\n",
    "                  verbose=False\n",
    "                  )\n",
    "    }\n",
    "\n",
    "print(f'completed to load data. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed to set env for all models. 2025-06-06 02:03:57.686414\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "## layers\n",
    "## LSTM Neural 계층 선언\n",
    "###########\n",
    "datasets = [dataset_dicts[1], # 0\n",
    "            dataset_dicts[2], # 1\n",
    "           ]\n",
    "\n",
    "sel_date = datetime(2025, 5, 31, 20, 35)\n",
    "rans_seed = (sel_date.timestamp() / 10000000)\n",
    "\n",
    "lstm_args = {14: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                           \"dropout\": dropout[0],\n",
    "                           \"steps\": steps[0], # last output elements count\n",
    "                           \"metrics\": metrics[1],\n",
    "                           \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                           \"lstm_units\": lstm_units[2],\n",
    "                           \"dense_units\": dense_units[2],\n",
    "                           \"output_dense_activation\": output_dense_activation[3],\n",
    "                           \"loss\": loss[0],\n",
    "                           \"return_state\": False,\n",
    "                           \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                           },\n",
    "                 \"train\": {\"epochs\": epochs[2],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 0 #100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             44: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                           \"dropout\": dropout[0],\n",
    "                           \"steps\": steps[0], # last output elements count\n",
    "                           \"metrics\": metrics[0],\n",
    "                           \"last_lstm_return_sequences\": last_lstm_return_sequences[1],\n",
    "                           \"lstm_units\": lstm_units[2],\n",
    "                           \"dense_units\": dense_units[2],\n",
    "                           \"output_dense_activation\": output_dense_activation[3],\n",
    "                           \"loss\": loss[0],\n",
    "                           \"return_state\": False,\n",
    "                           \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                           },\n",
    "                 \"train\": {\"epochs\": epochs[3],\n",
    "                           \"is_shuffle\": False,\n",
    "                           \"batch\": 1,\n",
    "                           \"steps_per_epoch\": 0 #100\n",
    "                           },\n",
    "                 \"dataset\": datasets[0]\n",
    "                 },\n",
    "             }\n",
    "lstm_args_4 = {4: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                            \"dropout\": dropout[1],\n",
    "                            \"steps\": steps[0], # last output elements count\n",
    "                            \"metrics\": metrics[0],\n",
    "                            \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                            \"lstm_units\": lstm_units[2],\n",
    "                            \"dense_units\": dense_units[2],\n",
    "                            \"output_dense_activation\": output_dense_activation[3],\n",
    "                            \"loss\": loss[1],\n",
    "                            \"return_state\": False,\n",
    "                            \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                            },\n",
    "                   \"train\": {\"epochs\": epochs[3],\n",
    "                             \"is_shuffle\": False,\n",
    "                             \"batch\": 3,\n",
    "                             \"steps_per_epoch\": 90 #100\n",
    "                             },\n",
    "                   \"dataset\": datasets[0]\n",
    "                   },\n",
    "             }\n",
    "lstm_args_14 = {14: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                              \"dropout\": dropout[0],\n",
    "                              \"steps\": steps[0], # last output elements count\n",
    "                              \"metrics\": metrics[1],\n",
    "                              \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                              \"lstm_units\": lstm_units[2],\n",
    "                              \"dense_units\": dense_units[2],\n",
    "                              \"output_dense_activation\": output_dense_activation[3],\n",
    "                              \"loss\": loss[0],\n",
    "                              \"return_state\": False,\n",
    "                              \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                              },\n",
    "                     \"train\": {\"epochs\": epochs[2],\n",
    "                               \"is_shuffle\": False,\n",
    "                               \"batch\": 1,\n",
    "                               \"steps_per_epoch\": 0 #100\n",
    "                               },\n",
    "                     \"dataset\": datasets[0]\n",
    "                     },\n",
    "                }\n",
    "\n",
    "lstm_args_44 = {44: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                              \"dropout\": dropout[0],\n",
    "                              \"steps\": steps[0], # last output elements count\n",
    "                              \"metrics\": metrics[0],\n",
    "                              \"last_lstm_return_sequences\": last_lstm_return_sequences[1],\n",
    "                              \"lstm_units\": lstm_units[2],\n",
    "                              \"dense_units\": dense_units[2],\n",
    "                              \"output_dense_activation\": output_dense_activation[3],\n",
    "                              \"loss\": loss[0],\n",
    "                              \"return_state\": False,\n",
    "                              \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                              },\n",
    "                     \"train\": {\"epochs\": epochs[3],\n",
    "                               \"is_shuffle\": False,\n",
    "                               \"batch\": 1,\n",
    "                               \"steps_per_epoch\": 0 #100\n",
    "                               },\n",
    "                     \"dataset\": datasets[0]\n",
    "                     },\n",
    "                }\n",
    "\n",
    "lstm_args_2 = {2: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                            \"dropout\": dropout[0],\n",
    "                            \"steps\": steps[0], # last output elements count\n",
    "                            \"metrics\": metrics[0],\n",
    "                            \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                            \"lstm_units\": lstm_units[1],\n",
    "                            \"dense_units\": dense_units[1],\n",
    "                            \"output_dense_activation\": output_dense_activation[0],\n",
    "                            \"loss\": loss[0],\n",
    "                            \"rand_seed\": rans_seed\n",
    "                            },\n",
    "                   \"train\": {\"epochs\": epochs[1],\n",
    "                             \"is_shuffle\": False,\n",
    "                             \"batch\": 1,\n",
    "                             \"steps_per_epoch\": 1\n",
    "                             },\n",
    "                   \"dataset\": datasets[0]\n",
    "                   },\n",
    "             }\n",
    "\n",
    "lstm_args_6 = {6: {\"model\":{\"learning_rate\": learning_rate[0],\n",
    "                            \"dropout\": dropout[1],\n",
    "                            \"steps\": steps[0], # last output elements count\n",
    "                            \"metrics\": metrics[0],\n",
    "                            \"last_lstm_return_sequences\": last_lstm_return_sequences[0],\n",
    "                            \"lstm_units\": lstm_units[5],\n",
    "                            \"dense_units\": dense_units[4],\n",
    "                            \"output_dense_activation\": output_dense_activation[3],\n",
    "                            \"loss\": loss[1],\n",
    "                            \"return_state\": False,\n",
    "                            \"lstm_model\": \"Bidirectional\",\n",
    "                            \"rand_seed\": rans_seed # rand_seed[0]\n",
    "                            },\n",
    "                   \"train\": {\"epochs\": epochs[3],\n",
    "                             \"is_shuffle\": False,\n",
    "                             \"batch\": 3,\n",
    "                             \"steps_per_epoch\": 90 #100\n",
    "                             },\n",
    "                   \"dataset\": datasets[0]\n",
    "                   }\n",
    "             }\n",
    "\n",
    "print(f'completed to set env for all models. {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_metric(test_id, gen_num, round_limit, lstm_args=lstm_args):\n",
    "    \"\"\" gen_metric \"\"\"\n",
    "    model_version_from = 1\n",
    "    model_version_end = 1\n",
    "    print(f'gen_metric.step.0 [{datetime.now()}]')\n",
    "    args = {'test_id': test_id,\n",
    "            'version': model_version_from,\n",
    "            'write_to_db': True,\n",
    "            'last': last,\n",
    "            'mode2': mode2,\n",
    "            'gen_num': gen_num,\n",
    "            'round_limit': round_limit,\n",
    "            'db_file_name': \"./db/metrics.db\"\n",
    "            }\n",
    "    print(f'gen_metric.step.1 [{datetime.now()}]')\n",
    "    generate_metric(args=args,\n",
    "                    from_version=model_version_from,\n",
    "                    to_version=model_version_end,\n",
    "                    lstm_args=lstm_args)\n",
    "    print(f'gen_metric.step.2 [{datetime.now()}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "100 [[0.60866486]\n",
      " [0.97236472]\n",
      " [0.77710796]\n",
      " [0.35091764]\n",
      " [0.80554561]\n",
      " [0.51913161]\n",
      " [0.39399478]\n",
      " [0.98327097]\n",
      " [0.6805912 ]\n",
      " [0.83559585]\n",
      " [0.62181561]\n",
      " [0.98444817]\n",
      " [0.49961473]\n",
      " [0.0887119 ]\n",
      " [0.64412002]\n",
      " [0.47457321]\n",
      " [0.80745311]\n",
      " [0.24197306]\n",
      " [0.81577368]\n",
      " [0.6624388 ]\n",
      " [0.28084521]\n",
      " [0.37725361]\n",
      " [0.31024711]\n",
      " [0.95477663]\n",
      " [0.99895754]\n",
      " [0.34078295]\n",
      " [0.61497541]\n",
      " [0.4037664 ]\n",
      " [0.54943021]\n",
      " [0.87660116]\n",
      " [0.8147247 ]\n",
      " [0.2122942 ]\n",
      " [0.59432807]\n",
      " [0.56620807]\n",
      " [0.80058453]\n",
      " [0.32185853]\n",
      " [0.14942534]\n",
      " [0.84781395]\n",
      " [0.3344445 ]\n",
      " [0.78013039]\n",
      " [0.74303363]\n",
      " [0.54396681]\n",
      " [0.30579648]\n",
      " [0.56877746]\n",
      " [0.9986796 ]\n",
      " [0.51552559]\n",
      " [0.25607482]\n",
      " [0.01877702]\n",
      " [0.62631895]\n",
      " [0.15337696]\n",
      " [0.71632987]\n",
      " [0.78712372]\n",
      " [0.40126322]\n",
      " [0.77350502]\n",
      " [0.06916975]\n",
      " [0.5585097 ]\n",
      " [0.58427634]\n",
      " [0.10029905]\n",
      " [0.25589849]\n",
      " [0.71533706]\n",
      " [0.64525251]\n",
      " [0.0275237 ]\n",
      " [0.37477366]\n",
      " [0.66604897]\n",
      " [0.19308536]\n",
      " [0.29327378]\n",
      " [0.05283367]\n",
      " [0.07035532]\n",
      " [0.79847317]\n",
      " [0.20946476]\n",
      " [0.52564884]\n",
      " [0.89111024]\n",
      " [0.67431783]\n",
      " [0.35540766]\n",
      " [0.74098823]\n",
      " [0.45746981]\n",
      " [0.58751386]\n",
      " [0.02042379]\n",
      " [0.78352695]\n",
      " [0.70058259]\n",
      " [0.70747827]\n",
      " [0.47874497]\n",
      " [0.61983254]\n",
      " [0.34756486]\n",
      " [0.36374533]\n",
      " [0.20892779]\n",
      " [0.49658011]\n",
      " [0.14400172]\n",
      " [0.14304764]\n",
      " [0.71611425]\n",
      " [0.07368329]\n",
      " [0.42816327]\n",
      " [0.5662053 ]\n",
      " [0.04228598]\n",
      " [0.82655439]\n",
      " [0.52293091]\n",
      " [0.53296088]\n",
      " [0.65298418]\n",
      " [0.28333128]\n",
      " [0.43505193]]\n",
      "1 [0.60866486]\n",
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2444\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0860\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0873\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0877\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0814\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0858\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0856\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0886\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0820\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0893\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0827  \n",
      "Test Loss: 0.08322419226169586\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0xfffef8735e40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predictions:\n",
      " [[0.48915192]\n",
      " [0.46241403]\n",
      " [0.4696356 ]\n",
      " [0.49512202]\n",
      " [0.48014387]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate sample data\n",
    "def generate_data(seq_length, num_samples):\n",
    "    rows = !echo \"select round, results\n",
    "  X = np.random.rand(num_samples, seq_length, 1)\n",
    "  y = np.random.rand(num_samples, 1)\n",
    "  return X, y\n",
    "\n",
    "# Define LSTM model\n",
    "def create_lstm_model(seq_length):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(50, activation='relu', input_shape=(seq_length, 1)))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(optimizer='adam', loss='mse')\n",
    "  return model\n",
    "\n",
    "# Parameters\n",
    "seq_length = 100\n",
    "num_samples = 1000\n",
    "\n",
    "# Generate data\n",
    "X_train, y_train = generate_data(seq_length, num_samples)\n",
    "# print(X_train, y_train)\n",
    "print(len(X_train))\n",
    "print(len(X_train[0]), X_train[0])\n",
    "print(len(X_train[0][0]), X_train[0][0])\n",
    "\n",
    "X_test, y_test = generate_data(seq_length, int(num_samples*0.2))\n",
    "\n",
    "# Create and train model\n",
    "model = create_lstm_model(seq_length)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Predictions:\\n\", predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Start: 1~1\n",
      "CPU 시간: 4.295898 초\n",
      "메모리 사용량: 616144 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 15:41:39.300424\n",
      "********************\n",
      "start to train all models. 2025-06-05 15:41:39.300454\n",
      "14's training. status=start 2025-06-05 15:41:39.300470\n",
      "14's training. status=end 2025-06-05 15:42:29.403099\n",
      "44's training. status=start 2025-06-05 15:42:29.403201\n",
      "44's training. status=end 2025-06-05 15:44:00.291719\n",
      "completed to train all models. 2025-06-05 15:44:00.291818\n",
      "train to create model(1). 2025-06-05 15:44:03.291901\n",
      "CPU 시간: 444.326674 초\n",
      "메모리 사용량: 1066912 KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_1'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 16:35:17.115076]\n",
      "gen_metric.step.1 [2025-06-05 16:35:17.115151]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 887.653416 초\n",
      "메모리 사용량: 1162592 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 16:35:17.115241\n",
      "********************\n",
      "start to train all models. 2025-06-05 16:35:17.115260\n",
      "14's training. status=start 2025-06-05 16:35:17.115277\n",
      "14's training. status=end 2025-06-05 16:36:06.258793\n",
      "completed to train all models. 2025-06-05 16:36:06.259092\n",
      "train to create model(1). 2025-06-05 16:36:09.259175\n",
      "CPU 시간: 1085.954814 초\n",
      "메모리 사용량: 1259808 KB\n",
      "gen_metric.step.2 [2025-06-05 16:39:02.396592]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_2'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 15:54:24.916540]\n",
      "gen_metric.step.1 [2025-06-05 15:54:24.916597]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 643.848371 초\n",
      "메모리 사용량: 1069264 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 15:54:24.916656\n",
      "********************\n",
      "start to train all models. 2025-06-05 15:54:24.916666\n",
      "44's training. status=start 2025-06-05 15:54:24.916676\n",
      "44's training. status=end 2025-06-05 15:55:54.581077\n",
      "completed to train all models. 2025-06-05 15:55:54.581205\n",
      "train to create model(1). 2025-06-05 15:55:57.581298\n",
      "CPU 시간: 886.626137 초\n",
      "메모리 사용량: 1162592 KB\n",
      "gen_metric.step.2 [2025-06-05 15:58:51.713842]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_3'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 18:03:06.790972]\n",
      "gen_metric.step.1 [2025-06-05 18:03:06.791049]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 1087.019035 초\n",
      "메모리 사용량: 1259808 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 18:03:06.791137\n",
      "********************\n",
      "start to train all models. 2025-06-05 18:03:06.791153\n",
      "4's training. status=start 2025-06-05 18:03:06.791167\n",
      "4's training. status=end 2025-06-05 18:04:01.033005\n",
      "completed to train all models. 2025-06-05 18:04:01.033137\n",
      "train to create model(1). 2025-06-05 18:04:04.033231\n",
      "CPU 시간: 1281.096318 초\n",
      "메모리 사용량: 1395776 KB\n",
      "gen_metric.step.2 [2025-06-05 18:06:54.907379]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_4'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-05 18:03:06.790972]\n",
      "gen_metric.step.1 [2025-06-05 18:03:06.791049]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 1087.019035 초\n",
      "메모리 사용량: 1259808 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-05 18:03:06.791137\n",
      "********************\n",
      "start to train all models. 2025-06-05 18:03:06.791153\n",
      "4's training. status=start 2025-06-05 18:03:06.791167\n",
      "4's training. status=end 2025-06-05 18:04:01.033005\n",
      "completed to train all models. 2025-06-05 18:04:01.033137\n",
      "train to create model(1). 2025-06-05 18:04:04.033231\n",
      "CPU 시간: 1281.096318 초\n",
      "메모리 사용량: 1395776 KB\n",
      "gen_metric.step.2 [2025-06-05 18:06:54.907379]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_5'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_metric.step.0 [2025-06-06 02:04:06.727261]\n",
      "gen_metric.step.1 [2025-06-06 02:04:06.727746]\n",
      "Test Start: 1~1\n",
      "CPU 시간: 1.78125 초\n",
      "메모리 사용량: 374760 KB\n",
      "generate_metric.02 args[\"version\"]=1\n",
      "********************\n",
      "working model_version = 1  2025-06-06 02:04:06.727820\n",
      "********************\n",
      "start to train all models. 2025-06-06 02:04:06.727829\n",
      "6's training. status=start 2025-06-06 02:04:06.727837\n",
      "6's training. status=end 2025-06-06 02:04:16.525473\n",
      "completed to train all models. 2025-06-06 02:04:16.525559\n",
      "train to create model(1). 2025-06-06 02:04:19.525649\n",
      "INFO:tensorflow:Assets written to: ram://4feacfa172b64cebbc81751509f72303/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4feacfa172b64cebbc81751509f72303/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU 시간: 35.375 초\n",
      "메모리 사용량: 1056312 KB\n",
      "gen_metric.step.2 [2025-06-06 02:05:25.607029]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# max_model_limit 정보만큼 반복적으로 매트릭을 생성합니다.\n",
    "#\n",
    "test_id = 'P4_6_1_6'\n",
    "gen_num = 1\n",
    "round_limit = 1000\n",
    "\n",
    "gen_metric(test_id=test_id, gen_num=gen_num, round_limit=round_limit, lstm_args=lstm_args_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
